
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8" />
    <title>yty的博客</title>
    <meta name="author" content="Leo yu yty" />
    <meta name="description" content="Hello Everyone This is my website" />
    <meta name="keywords" content="" />
    <meta
        name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"
    />
    <link rel="icon" href="/images/xnylh.webp" />
    <link rel="preconnect" href="https://s4.zstatic.net" />
<script src="https://s4.zstatic.net/ajax/libs/vue/3.3.7/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
<link rel="preconnect" href="https://fonts.googleapis.cn" />
<link rel="preconnect" href="https://fonts.gstatic.cn" crossorigin />
<link
    rel="stylesheet"
    href="https://fonts.googleapis.cn/css2?family=Fira+Code:wght@400;500;600;700&family=Lexend:wght@400;500;600;700;800;900&family=Noto+Sans+SC:wght@400;500;600;700;800;900&display=swap"
/>
<script> const mixins = {}; </script>

<script src="https://polyfill.alicdn.com/v3/polyfill.min.js?features=default"></script>


<script src="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<link
    rel="stylesheet"
    href="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>



<script src="/js/lib/preview.js"></script>





<script src="/js/lib/home.js"></script>

<link rel="stylesheet" href="/css/main.css" />

<meta name="generator" content="Hexo 8.1.1"></head>
<body>
    <div id="layout">
        <transition name="fade">
            <div id="loading" v-show="loading">
                <div id="loading-circle">
                    <h2>LOADING</h2>
                    <p>加载过慢请开启缓存 浏览器默认开启</p>
                    <img src="/images/loading.gif" />
                </div>
            </div>
        </transition>
        <div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <nav id="desktop-menu">
        <a class="title" href="/">
            <span>YTY的博客</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;主页</span>
        </a>
        
        <a href="/about/">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;关于</span>
        </a>
        
        <a href="/archives/">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;文章</span>
        </a>
        
        <a href="/categories/">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;分类</span>
        </a>
        
        <a href="/tags/">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;标签</span>
        </a>
        
    </nav>
    <nav id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;YTY的博客</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">主页</div>
                    </div>
                </a>
                
                <a href="/about/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">关于</div>
                    </div>
                </a>
                
                <a href="/archives/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">文章</div>
                    </div>
                </a>
                
                <a href="/categories/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">分类</div>
                    </div>
                </a>
                
                <a href="/tags/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">标签</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </nav>
</div>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

        <div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'">
            <div id="home-head">
    <div
        id="home-background"
        ref="homeBackground"
        data-images="/images/6.png"
    ></div>
    <div id="home-info" @click="homeClick">
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="info">
            <div class="wrap">
                <h1>yty的博客</h1>
                <h3>yty的日常博客记录</h3>
                <h5>Hello Everyone This is my website</h5>
            </div>
        </span>
    </div>
</div>
<div
    id="home-posts-wrap"
    ref="homePostsWrap"
    true
>
    <div id="home-posts">
        

<div class="post">
    <a href="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/">
        <h2 class="post-title">K-近邻模型</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                复习笔记
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/12/11
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="K-近邻模型"><a href="#K-近邻模型" class="headerlink" title="K - 近邻模型"></a>K - 近邻模型</h2><h3 id="一、聚合思想"><a href="#一、聚合思想" class="headerlink" title="一、聚合思想"></a>一、聚合思想</h3><h5 id="定义：把数据集中的个体值进行统计汇总，通过一个概括值（如：平均数、众数、中位数）来反映整个数据集"><a href="#定义：把数据集中的个体值进行统计汇总，通过一个概括值（如：平均数、众数、中位数）来反映整个数据集" class="headerlink" title="定义：把数据集中的个体值进行统计汇总，通过一个概括值（如：平均数、众数、中位数）来反映整个数据集"></a>定义：把数据集中的个体值进行统计汇总，通过一个概括值（如：平均数、众数、中位数）来反映整个数据集</h5><p>人话：选几个邻居，参考邻居的情况预测自己的</p>
<p>先找目标对象“最近的K个邻居”：</p>
<ul>
<li>分类问题中，采用【众数思想】，用邻居里最多的类别作为最后答案</li>
<li>回归问题中，采用【均值思想】，用邻居的平均值作为预测值</li>
</ul>
<h5 id="分类问题-v-s-回归问题："><a href="#分类问题-v-s-回归问题：" class="headerlink" title="分类问题 v.s. 回归问题："></a>分类问题 v.s. 回归问题：</h5><p>考点：监督学习中，根据输出空间不同，可以将其分为两类问他：回归问题&amp;分类问题</p>
<ul>
<li><p>分类问题：输出空间由离散数值构成，最终预测的是【类别】</p>
<ul>
<li>如：根据用户的浏览记录，预测 TA 是 “男性” 还是 “女性” —— 预测结果为类别</li>
</ul>
</li>
<li><p>回归问题：输出空间由连续性数值构成，最终预测的是【数值】</p>
<ul>
<li>如：根据房子的面积、楼层，预测房子的 “成交价格” —— 预测结果为具体数字</li>
</ul>
</li>
</ul>
<h5 id="K-近邻算法的关键影响因素"><a href="#K-近邻算法的关键影响因素" class="headerlink" title="K - 近邻算法的关键影响因素"></a>K - 近邻算法的关键影响因素</h5><ul>
<li>K的取值：即选几个邻居</li>
<li>距离的定义：哪些邻居算作为和自己比较“像”的，“距离”既是如何评判“像”的标准</li>
<li>决策规则：除了用【众数】、【平均数】、还可以用【中位数】</li>
</ul>
<h5 id="1）K-近邻分类算法（预测“类别”）"><a href="#1）K-近邻分类算法（预测“类别”）" class="headerlink" title="1）K - 近邻分类算法（预测“类别”）"></a>1）K - 近邻分类算法（预测“类别”）</h5><img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/1.png" class="" title="图片描述">

<p>符号含义：</p>
<img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/2.png" class="" title="图片描述">

<p>输入：</p>
<ul>
<li>训练集T：样本：{ 特征（xi）+<u>类别</u>（yi）}；yi 属于 {苹果，橘子}（也就是算法里的 {c₁,c₂,…,cₘ}）</li>
<li>待分类实例 x*（即要判断的新样本）</li>
</ul>
<p>输出：</p>
<ul>
<li>x* 的类别</li>
</ul>
<p>三个步骤：</p>
<ul>
<li>算距离：计算 x* 与训练集里面每个已知的样本的 “相似度” 距离</li>
<li>选邻居：从训练集中挑出和 x* 最像的K个样本</li>
<li>做决策：根据分类决策【众数思想】，将最多的那个类别作为 x* 的预测结果</li>
</ul>
<h5 id="2）K-近邻回归算法（预测“数值”）"><a href="#2）K-近邻回归算法（预测“数值”）" class="headerlink" title="2）K - 近邻回归算法（预测“数值”）"></a>2）K - 近邻回归算法（预测“数值”）</h5><img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/3.png" class="" title="图片描述">

<p>猜水果重量情境</p>
<p>输入：</p>
<ul>
<li>训练集T：样本：{ 特征（xi）+<u>数值</u>（yi）}；yi 属于 “实数（ℝ）”</li>
<li>待分类实例 x*（即要猜重量的新水果）</li>
</ul>
<p>输出：</p>
<ul>
<li>x* 的预测数值（新水果重多少多少克比如）</li>
</ul>
<p>三个步骤：</p>
<ul>
<li>算距离：计算新水果 x* 和训练集里每个已知水果的”相似度距离“</li>
<li>选邻居：挑出和 x* 最像的K个水果</li>
<li>做决策：回归问题【均值思想】，取这K个水果的平均值作为 x* 的预测重量</li>
</ul>
<h3 id="二、K-近邻算法的三要素"><a href="#二、K-近邻算法的三要素" class="headerlink" title="二、K - 近邻算法的三要素"></a>二、K - 近邻算法的三要素</h3><h4 id="1）距离度量（如何计算“相似度距离”）"><a href="#1）距离度量（如何计算“相似度距离”）" class="headerlink" title="1）距离度量（如何计算“相似度距离”）"></a>1）距离度量（如何计算“相似度距离”）</h4><ul>
<li><h5 id="曼哈顿距离-绝对距离之和"><a href="#曼哈顿距离-绝对距离之和" class="headerlink" title="曼哈顿距离 - 绝对距离之和"></a>曼哈顿距离 - 绝对距离之和</h5><ul>
<li>定义：所有属性下的绝对距离之和</li>
</ul>
<img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/4.png" class="" title="图片描述">
</li>
<li><h5 id="欧式距离-平方和，再开平方根"><a href="#欧式距离-平方和，再开平方根" class="headerlink" title="欧式距离 - 平方和，再开平方根"></a>欧式距离 - 平方和，再开平方根</h5><ul>
<li>定义：所有属性下的平方距离之和的非负平方根</li>
</ul>
<img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/5.png" class="" title="图片描述">
</li>
<li><h5 id="切比雪夫距离-最大绝对距离"><a href="#切比雪夫距离-最大绝对距离" class="headerlink" title="切比雪夫距离 - 最大绝对距离"></a>切比雪夫距离 - 最大绝对距离</h5><ul>
<li>定义：所有属性下绝对距离的最大值</li>
</ul>
<img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/6.png" class="" title="图片描述">
</li>
<li><h5 id="闵可夫斯基距离-万能公式，前面三种距离都是它的特例"><a href="#闵可夫斯基距离-万能公式，前面三种距离都是它的特例" class="headerlink" title="闵可夫斯基距离 - 万能公式，前面三种距离都是它的特例"></a>闵可夫斯基距离 - 万能公式，前面三种距离都是它的特例</h5><img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/7.png" class="" title="图片描述">

<ul>
<li>s &#x3D; 1时，曼哈顿距离</li>
<li>s &#x3D; 2时，欧氏距离</li>
<li>s &#x3D; 无穷大，切比雪夫距离</li>
</ul>
</li>
<li><h5 id="汉明距离-属性特征为“离散变量”时，运用"><a href="#汉明距离-属性特征为“离散变量”时，运用" class="headerlink" title="汉明距离 - 属性特征为“离散变量”时，运用"></a>汉明距离 - 属性特征为“离散变量”时，运用</h5><ul>
<li>定义：表示两个等长的字符串在对应位置上字符不同的情况的出现次数</li>
</ul>
<img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/8.png" class="" title="图片描述"></li>
</ul>
<h4 id="2）决策规则"><a href="#2）决策规则" class="headerlink" title="2）决策规则"></a>2）决策规则</h4><ul>
<li>分类问题：众数思想</li>
<li>回归问题：均值思想</li>
</ul>
<h4 id="3）K值的选取-选几个最像的邻居"><a href="#3）K值的选取-选几个最像的邻居" class="headerlink" title="3）K值的选取 - 选几个最像的邻居"></a>3）K值的选取 - 选几个最像的邻居</h4><img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/9.png" class="" title="图片描述">

<p>注：</p>
<p>关于 𝐾 值的选取可采用<u>交叉验证</u>（即多试几个K的值，选 MSE 最小的那个）的方法，通过方差-偏差折中思想，实现 MSE （均方误差）最小化。</p>
<p>一般来说，选取的 <u>𝐾 值低于训练集中样本容量的平方根 √N</u>。</p>
<p>均方误差：MSE &#x3D; 方差 + 偏差 ²+ 噪声</p>
<p>总结：</p>
<ul>
<li>K太大：偏差、欠拟合</li>
<li>K太小：方差、过拟合</li>
</ul>
<p>注：方差项由抽样带来；偏差项由模型选择带来</p>
<h4 id="4）K维树-快速找到相似的邻居"><a href="#4）K维树-快速找到相似的邻居" class="headerlink" title="4）K维树 - 快速找到相似的邻居"></a>4）K维树 - 快速找到相似的邻居</h4><p>定义：本质为二叉树，表示对【k维属性特征空间的一个划分】</p>
<p>优点：k维树能够【快速检索】训练集中的样本</p>
<p>人话：k维树的作用时把“高维特征空间”（样本有几个特征，就是几维空间；如样本特征为“大小、颜色”，就是二维空间）切成一块一块的小区域。</p>
<ul>
<li>要找 “和苹果 A 最像的邻居”，不用把所有水果都比一遍，而是先通过 K 维树找到 “苹果 A 所在的小区域”，再在这个区域里找邻居，速度更快。</li>
<li>时间复杂度： <em>O</em>(<em>p</em>log<em>N</em>)（p 是特征维度，N 是样本数）</li>
</ul>
<h4 id="a、K维树的构建-分层切分空间"><a href="#a、K维树的构建-分层切分空间" class="headerlink" title="a、K维树的构建 - 分层切分空间"></a>a、K维树的构建 - 分层切分空间</h4><p>构建K维树 &#x3D; 反复用和坐标轴垂直的线将空间切成两半</p>
<p>【平衡K维树：根据坐标轴上的中位数作为切分点的K维树称为平衡K维树】</p>
<h5 id="步骤："><a href="#步骤：" class="headerlink" title="步骤："></a>步骤：</h5><ul>
<li><h5 id="选择切分特征【构造根节点】"><a href="#选择切分特征【构造根节点】" class="headerlink" title="选择切分特征【构造根节点】"></a>选择切分特征【构造根节点】</h5><ul>
<li>最优特征的选择：选择【<u>样本方差最大</u>】的特征作为最优特征，作为坐标轴</li>
</ul>
</li>
<li><h5 id="找切分点【选好特征的样本中位数即为“切分点”】"><a href="#找切分点【选好特征的样本中位数即为“切分点”】" class="headerlink" title="找切分点【选好特征的样本中位数即为“切分点”】"></a>找切分点【选好特征的样本中位数即为“切分点”】</h5></li>
<li><h5 id="重复切割"><a href="#重复切割" class="headerlink" title="重复切割"></a>重复切割</h5><ul>
<li>根据【剩余特征】的方差（还是选样本方差最大的特征）选择当前最优特征</li>
<li>用一个特征切完要换另外一个特征</li>
</ul>
</li>
<li><h5 id="停止"><a href="#停止" class="headerlink" title="停止"></a>停止</h5><ul>
<li>【直到子区域没有实例时停止切割】得到平衡k维树</li>
<li>人话：直到每个区域都只有一个样本</li>
</ul>
</li>
</ul>
<h5 id="例题："><a href="#例题：" class="headerlink" title="例题："></a>例题：</h5><img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/10.png" class="" title="图片描述">

<ul>
<li>x1的样本：{1，2，3，4，5，7，8}</li>
<li>x2的样本：{6，7，2，9，5，8，4}</li>
</ul>
<h6 id="第一次切割："><a href="#第一次切割：" class="headerlink" title="第一次切割："></a>第一次切割：</h6><ul>
<li>x1样本方差大，x1作为【切分特征】</li>
<li>x1中位数为：4，对应样本（4，9）—— 这个就是【根节点】</li>
<li>垂直于x1轴，过x1 &#x3D; 4的线，切割</li>
</ul>
<h6 id="第一次切割得到的左右两个切分空间："><a href="#第一次切割得到的左右两个切分空间：" class="headerlink" title="第一次切割得到的左右两个切分空间："></a>第一次切割得到的左右两个切分空间：</h6><ul>
<li>左区域：<em>x</em>1≤4 → 样本是 (1,6),(2,7),(3,2),(4,9)</li>
<li>右区域：<em>x</em>1&gt;4 → 样本是 (5,5),(7,8),(8,4)</li>
</ul>
<h6 id="第二次切割（左区域）："><a href="#第二次切割（左区域）：" class="headerlink" title="第二次切割（左区域）："></a>第二次切割（左区域）：</h6><ul>
<li>左区域样本：(1,6),(2,7),(3,2),(4,9)</li>
<li>第一次用x1切割，这次换一个特征：用x2作为切分特征</li>
<li>x2的样本：{6，7，2，9}，中位数：6.5，对应样本为（1，6）或者（2，7），随便选一个，用（1，6）作为子节点</li>
<li>切割：垂直于x2，过x2 &#x3D; 6</li>
</ul>
<h6 id="等等等，直到【每个区域只有一个样本】"><a href="#等等等，直到【每个区域只有一个样本】" class="headerlink" title="等等等，直到【每个区域只有一个样本】"></a>等等等，直到【每个区域只有一个样本】</h6><img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/11.png" class="" title="图片描述">

<h4 id="b、K维树的搜索-用k维树找到和目标样本最像的邻居"><a href="#b、K维树的搜索-用k维树找到和目标样本最像的邻居" class="headerlink" title="b、K维树的搜索 - 用k维树找到和目标样本最像的邻居"></a>b、K维树的搜索 - 用k维树找到和目标样本最像的邻居</h4><p><strong>K维树的最近邻搜索从【根结点出发】，分为两步：</strong></p>
<ul>
<li><strong>搜索当前最近点</strong></li>
<li><strong>回溯验证</strong> - 用与其他样本间求欧式距离验证是否为最小</li>
</ul>
<p>例题1：</p>
<img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/12.png" class="" title="图片描述">

<p>解答：</p>
<img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/13.png" class="" title="图片描述">

<p>例题2：</p>
<img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/14.png" class="" title="图片描述">

<p>解答：</p>
<img src="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/15.png" class="" title="图片描述">

<h3 id="三、习题"><a href="#三、习题" class="headerlink" title="三、习题"></a>三、习题</h3><p>1）在K-近邻算法中，小明通过小芳朋友们的动向来判断小芳可能去哪个食堂，这体现了K-近邻算法的哪种基本思想？</p>
<p>答：【邻友思想】</p>
<p>2）在K-近邻模型中，分类问题通常采用的决策规律是</p>
<p>答：【众数思想】</p>
<p>3）在K-近邻算法中，使用欧氏距离作为距离度量时，特征空间的划分形状通常为</p>
<p>答：【球形&#x2F;圆形】</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E7%AC%94%E8%AE%B0/" style="color: #00a596">笔记</a>
        </span>
        
    </div>
    <a href="/2025/12/11/K-%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/">
        <h2 class="post-title">大数据探索分析课程基础</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                复习笔记
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/12/10
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="大数据探索性分析基本流程"><a href="#大数据探索性分析基本流程" class="headerlink" title="大数据探索性分析基本流程"></a>大数据探索性分析基本流程</h2><p>**1）理解数据：**了解数据的结构、质量（缺失值、错误值、重复值）、分布（数据取值范围、集中趋势 - 均值&#x2F;中位数、离散程度 - 方差&#x2F;标准差）等规律</p>
<p>**2）发现线索：**识别趋势、异常值、关联</p>
<p>**3）形成假设：**针对线索，生成可验证的假设</p>
<p>**4）检查前提：**有很多数据分析模型（如：回归分析，方差分析）都有明确的适用前提，如：正态性（数据分布符合正态分布）、独立性（样本之间无关联）</p>
<p>**5）建模准备：**包括数据清洗、特征工程（标准化&#x2F;归一化）</p>
<h2 id="一、数据形式内容"><a href="#一、数据形式内容" class="headerlink" title="一、数据形式内容"></a>一、数据形式内容</h2><h4 id="数据的形式（偏概念）"><a href="#数据的形式（偏概念）" class="headerlink" title="数据的形式（偏概念）"></a>数据的形式（偏概念）</h4><p>**1）结构化数据：**以行和列存储，具有固定格式和明确字段含义的数据（便于计算机直接读取的数据）</p>
<p>**核心分析方法：**SQL查询、回归分析（线性回归预测连续型变量；逻辑回归预测分类型变量）</p>
<p>**2）非结构化数据：**无固定格式的数据，需要通过半结构化处理才能被分析的数据</p>
<p>**核心分析方法：**自然语言处理、计算机视觉、语音识别</p>
<p>**数据元素的类型：**数值型、字符型、布尔值、日期时间型、列表型、字典型</p>
<p>**属性的类型：**类别型、序数型、区间型、比率型</p>
<h4 id="数据点的相似性度量"><a href="#数据点的相似性度量" class="headerlink" title="数据点的相似性度量"></a>数据点的相似性度量</h4><h5 id="纯数值型属性情况："><a href="#纯数值型属性情况：" class="headerlink" title="纯数值型属性情况："></a>纯数值型属性情况：</h5><img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/1.png" class="" title="图片描述">

<h5 id="纯类别型属性情况："><a href="#纯类别型属性情况：" class="headerlink" title="纯类别型属性情况："></a>纯类别型属性情况：</h5><img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/2.png" class="" title="图片描述">

<p>简单匹配系数方法适用于有重复类别的情况；Jaccard系数方法适用于无重复类别的情况</p>
<p>简单匹配系数案例：</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/24.png" class="" title="图片描述">

<h5 id="纯序数型属性情况："><a href="#纯序数型属性情况：" class="headerlink" title="纯序数型属性情况："></a>纯序数型属性情况：</h5><img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/3.png" class="" title="图片描述">

<h5 id="混合型属性情况："><a href="#混合型属性情况：" class="headerlink" title="混合型属性情况："></a>混合型属性情况：</h5><p>案例：</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/4.png" class="" title="图片描述">

<p>解答：</p>
<p>目标：比较A与B像不像</p>
<p><strong>step 1：计算每个属性的局部距离（不像程度）</strong></p>
<p><strong>1）年龄（数值属性）</strong></p>
<p>局部距离 &#x3D; A(35)与B(28)年龄差 &#x2F; 年龄最大范围差 （这里年龄最大范围假设为18 - 70，差为52) &#x3D; 0.135</p>
<p><strong>2）性别（二元属性）</strong></p>
<p>二人不同性别，局部距离 &#x3D; 1</p>
<p><strong>3）教育程度（序数属性）</strong></p>
<p>把学历按 “高中 &#x3D; 1、学士 &#x3D; 2、硕士 &#x3D; 3、博士 &#x3D; 4” 排顺序</p>
<p>局部距离 &#x3D; A(3)与B(2)的差 &#x2F; 学历最大范围差(4-1&#x3D;3) &#x3D; 0.333</p>
<p><strong>4）购买类别（类别属性）</strong></p>
<p>由于二者完全没有重叠部分，采用Jaccard方法计算</p>
<p>局部距离 &#x3D; 1-(重叠数&#x2F;总类别数) &#x3D; 1</p>
<p><strong>总结一下这部分：</strong></p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/5.png" class="" title="图片描述">

<p><strong>step 2：设置权重，计算加权距离（加权距离为：对应属性权重 * 对应局部距离）</strong></p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/6.png" class="" title="图片描述">

<p>—— 0表示完全相同，1表示完全不同。</p>
<h2 id="二、描述型统计"><a href="#二、描述型统计" class="headerlink" title="二、描述型统计"></a>二、描述型统计</h2><h4 id="集中趋势概念：均值、中位数、众数"><a href="#集中趋势概念：均值、中位数、众数" class="headerlink" title="集中趋势概念：均值、中位数、众数"></a>集中趋势概念：均值、中位数、众数</h4><img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/7.png" class="" title="图片描述">

<h4 id="离散程度："><a href="#离散程度：" class="headerlink" title="离散程度："></a>离散程度：</h4><p><strong>1）标准差</strong></p>
<p>**2）变异系数：**消除测量尺度和量纲的影响</p>
<p>如：身高用厘米、体重用公斤，单位不一样没法直接比波动？这时候用变异系数：把标准差除以平均值，去掉单位影响。</p>
<p>**3）极差：**最大数-最小数</p>
<p>**4）四分位差：**先把数据排好队，分成 4 等份，取中间那一半的范围（第 3 份减第 1 份）。不管两头的极端值，只看中间大多数数据的波动。</p>
<h4 id="分布形态：偏度、峰度"><a href="#分布形态：偏度、峰度" class="headerlink" title="分布形态：偏度、峰度"></a>分布形态：偏度、峰度</h4><p><strong>1）偏度</strong>（衡量数据偏移程度）- 偏不偏？</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/8.png" class="" title="图片描述">

<p><strong>2）峰度</strong>（衡量数据集中趋势的指标）- 尖不尖？</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/9.png" class="" title="图片描述">

<p>偏度是绝对指标、峰度是相对指标</p>
<h5 id="Q1：如何计算样本偏度和峰度？"><a href="#Q1：如何计算样本偏度和峰度？" class="headerlink" title="Q1：如何计算样本偏度和峰度？"></a>Q1：如何计算样本偏度和峰度？</h5><p><strong>1）计算样本偏度</strong></p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/10.png" class="" title="图片描述">

<p>样本偏度公式：</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/11.png" class="" title="图片描述">

<p><strong>2）计算样本峰度</strong></p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/12.png" class="" title="图片描述">

<h5 id="Q2：方差、偏度、峰度的联系？"><a href="#Q2：方差、偏度、峰度的联系？" class="headerlink" title="Q2：方差、偏度、峰度的联系？"></a>Q2：方差、偏度、峰度的联系？</h5><p>都是描述数据分布特征的指标</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/13.png" class="" title="图片描述">

<h2 id="三、属性类型与统计方法的适配"><a href="#三、属性类型与统计方法的适配" class="headerlink" title="三、属性类型与统计方法的适配"></a>三、属性类型与统计方法的适配</h2><h4 id="1）类别型属性"><a href="#1）类别型属性" class="headerlink" title="1）类别型属性"></a>1）类别型属性</h4><ul>
<li>核心统计方法：<br>- 频数：某类别的出现次数<br>- 频率：某类别出现次数占总数的比例</li>
<li>图表：柱状图、饼图</li>
</ul>
<h4 id="2）序数型属性（数据有顺序-等级，但没有固定的数值间隔）"><a href="#2）序数型属性（数据有顺序-等级，但没有固定的数值间隔）" class="headerlink" title="2）序数型属性（数据有顺序&#x2F;等级，但没有固定的数值间隔）"></a>2）序数型属性（数据有顺序&#x2F;等级，但没有固定的数值间隔）</h4><ul>
<li>核心统计方法：<br>- 累积频数：从低到高（或高到低）累加的次数（比如 “优 + 良” 的累积频数 &#x3D; 优的频数 + 良的频数）<br>- 等级相关分析：看两个序数数据的 “顺序关联”（比如 “成绩等级” 和 “作业完成等级” 是否正相关）</li>
</ul>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/14.png" class="" title="图片描述">

<ul>
<li>图表：折线图、箱线图</li>
</ul>
<h4 id="3）区间型属性"><a href="#3）区间型属性" class="headerlink" title="3）区间型属性"></a>3）区间型属性</h4><ul>
<li>核心统计方法：均值、方差</li>
<li>图表：直方图、散点图</li>
</ul>
<h4 id="4）比率型属性"><a href="#4）比率型属性" class="headerlink" title="4）比率型属性"></a>4）比率型属性</h4><ul>
<li>核心统计方法：均值、标准差、相关系数（看两个比率数据的 “线性关联强度”（比如 “身高” 和 “体重” 的相关程度））</li>
<li>图表：折线图、散点图</li>
</ul>
<h2 id="四、缺失值"><a href="#四、缺失值" class="headerlink" title="四、缺失值"></a>四、缺失值</h2><h4 id="1）缺失值的分类："><a href="#1）缺失值的分类：" class="headerlink" title="1）缺失值的分类："></a>1）缺失值的分类：</h4><ul>
<li>完全随机缺失：缺失与任何变量无关，仅由随机因素导致</li>
<li>随机缺失：缺失与已观测变量相关，但与缺失变量本身无关</li>
<li>非随机缺失：缺失与缺失变量本身直接相关</li>
</ul>
<h4 id="2）缺失数据的处理步骤"><a href="#2）缺失数据的处理步骤" class="headerlink" title="2）缺失数据的处理步骤"></a>2）缺失数据的处理步骤</h4><p>识别缺失值——探索缺失值的分布模式——分析导致缺失的原因——处理缺失值</p>
<h4 id="3）缺失值的处理"><a href="#3）缺失值的处理" class="headerlink" title="3）缺失值的处理"></a>3）缺失值的处理</h4><ul>
<li><strong>删除法：</strong><ul>
<li>行删除&amp;列删除</li>
</ul>
</li>
<li><strong>代表性性数据填充：</strong><ul>
<li>均值填充：适用于服从正态分布的数值型变量</li>
<li>中位数填充：适用于存在极端值的偏态分布</li>
<li>众数填充：适用于离散型分布变量</li>
<li>前向填充&#x2F;后向填充：适用于时间序列数据（如：今天的数字空了，就用明天的或者昨天的数据填充）</li>
</ul>
</li>
<li><strong>预测法填充：</strong><ul>
<li>回归填充：通过与缺失值有关联的变量建立回归模型，从而预测缺失值</li>
<li>KNN填充：找k个与缺失值相似情况的值，取他们的均值从而填充缺失值</li>
</ul>
</li>
</ul>
<h2 id="五、异常值（-离群点）"><a href="#五、异常值（-离群点）" class="headerlink" title="五、异常值（&#x3D; 离群点）"></a>五、异常值（&#x3D; 离群点）</h2><h3 id="1、概念部分"><a href="#1、概念部分" class="headerlink" title="1、概念部分"></a>1、概念部分</h3><h4 id="1）异常值的来源"><a href="#1）异常值的来源" class="headerlink" title="1）异常值的来源"></a>1）异常值的来源</h4><ul>
<li>数据来源于不同的类</li>
<li>自然变异</li>
<li>数据测量和收集误差</li>
<li>业务特征</li>
</ul>
<h4 id="2）异常值的类型"><a href="#2）异常值的类型" class="headerlink" title="2）异常值的类型"></a>2）异常值的类型</h4><ul>
<li>点异常值</li>
<li>上下文异常值</li>
<li>集体异常值</li>
</ul>
<h4 id="3）判断异常值需要注意"><a href="#3）判断异常值需要注意" class="headerlink" title="3）判断异常值需要注意"></a>3）判断异常值需要注意</h4><ul>
<li>确定数据对象是单一属性异常还是多个属性异常</li>
<li>异常值的全局观点和局部观点（数据是否异常需要考虑其所对比对象）</li>
<li>数据对象的异常程度</li>
<li>多个数据对象同时考虑看有没有异常</li>
</ul>
<h3 id="2、异常值检测"><a href="#2、异常值检测" class="headerlink" title="2、异常值检测"></a>2、异常值检测</h3><h4 id="1）基于统计方法检测异常值"><a href="#1）基于统计方法检测异常值" class="headerlink" title="1）基于统计方法检测异常值"></a>1）基于统计方法检测异常值</h4><h5 id="a、基于z-score的异常值检测"><a href="#a、基于z-score的异常值检测" class="headerlink" title="a、基于z-score的异常值检测"></a>a、基于z-score的异常值检测</h5><p>适用于：单变量+正态分布</p>
<p>z的值 &#x3D; （当前值 - 均值）&#x2F; 标准差</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/15.png" class="" title="图片描述">

<h5 id="b、基于箱线图的检测"><a href="#b、基于箱线图的检测" class="headerlink" title="b、基于箱线图的检测"></a>b、基于箱线图的检测</h5><p>箱线图（&#x3D; 盒须图）：由中位数Q2、下四分位数Q1、上四分位数Q3构成的箱体以及两个表示数据范围的须线组成，超出上下边缘的值为异常值。</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/16.png" class="" title="图片描述">

<h5 id="c、基于假设检验的检测"><a href="#c、基于假设检验的检测" class="headerlink" title="c、基于假设检验的检测"></a>c、基于假设检验的检测</h5><p>（适合数据少+只有一个异常值点+正态分布的情况）——（可以支持多变量）</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/17.png" class="" title="图片描述">

<p>用算出来的G，查表检验（G是否&gt;临界点）该值是否显著，若显著（&gt;），则该点为异常值点。</p>
<h4 id="2）基于局部离群因子检测异常值"><a href="#2）基于局部离群因子检测异常值" class="headerlink" title="2）基于局部离群因子检测异常值"></a>2）基于局部离群因子检测异常值</h4><h5 id="局部离群因子（LOF）"><a href="#局部离群因子（LOF）" class="headerlink" title="局部离群因子（LOF）"></a>局部离群因子（LOF）</h5><p>定义：通过评估数据对象相对于其局部邻近区域的离群程度来检测异常点，不是通过全局尺度来判定。</p>
<p>异常点位于局部密度较低的区域；正常点位于局部密度较高的区域。</p>
<p>LOF通过比较每个点的局部密度来判断该点是否为异常点。</p>
<ul>
<li><h5 id="计算局部离群因子（LOF）"><a href="#计算局部离群因子（LOF）" class="headerlink" title="计算局部离群因子（LOF）"></a>计算局部离群因子（LOF）</h5></li>
</ul>
<p><strong>step1：</strong></p>
<p>对数据集中每个点选取k个离他最近的点</p>
<p><strong>step2：</strong></p>
<p>计算k - 距离**（k - distance）&#x3D; 每个数据点p到与他的第k个最近点ok之间的距离**</p>
<p>ok又被称为点p的第k个最近邻</p>
<p>如：第五个点离该点2米，则k - 距离就为2米</p>
<p><strong>step3：</strong></p>
<p>定义<strong>可达距离</strong>（平滑点之间的距离，避免由于局部过于密集的区域导致的异常点识别误差）</p>
<p>当前点为p</p>
<p><strong>可达距离 &#x3D; max（o点的k - 距离，p到o之间的距离）</strong></p>
<p>简单来讲：可达距离 &#x3D; max (邻居的 k - 距离，点到邻居的实际距离)</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/18.png" class="" title="图片描述">

<p><strong>step4：</strong></p>
<p><strong>局部可达密度（LRD）：邻居到该点的平均可达距离的倒数（密度越高，值越大）</strong></p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/19.png" class="" title="图片描述">

<p><strong>step5：</strong></p>
<p><strong>计算局部离群因子（LOF）</strong></p>
<p>LOF接近于1——为正常点</p>
<p>LOF&gt;1——为异常点</p>
<p>LOF值越大，离群程度越高</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/20.png" class="" title="图片描述">

<ul>
<li>k值的影响：k太小，局部信息不够，容易误判；k值越大，异常点会被漏掉</li>
</ul>
<h4 id="3）基于聚类检测异常值（k-means聚类）"><a href="#3）基于聚类检测异常值（k-means聚类）" class="headerlink" title="3）基于聚类检测异常值（k - means聚类）"></a>3）基于聚类检测异常值（k - means聚类）</h4><ul>
<li><h5 id="k-means聚类定义："><a href="#k-means聚类定义：" class="headerlink" title="k - means聚类定义："></a>k - means聚类定义：</h5></li>
</ul>
<p>把所有数据点分为k个簇（k个小团体），计算每个点到自己所属簇的中心的距离，根据这一距离设定阈值，大于这一阈值的被称为离群点。</p>
<p>阈值选择：</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/21.png" class="" title="图片描述">

<ul>
<li><h5 id="k-means聚类的优缺点："><a href="#k-means聚类的优缺点：" class="headerlink" title="k - means聚类的优缺点："></a>k - means聚类的优缺点：</h5></li>
</ul>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/22.png" class="" title="图片描述">

<h4 id="3）基于聚类检测异常值（DBSCAN聚类）"><a href="#3）基于聚类检测异常值（DBSCAN聚类）" class="headerlink" title="3）基于聚类检测异常值（DBSCAN聚类）"></a>3）基于聚类检测异常值（DBSCAN聚类）</h4><ul>
<li><h5 id="DBSCAN聚类定义："><a href="#DBSCAN聚类定义：" class="headerlink" title="DBSCAN聚类定义："></a>DBSCAN聚类定义：</h5></li>
</ul>
<p>两个重要参数：<strong>最小邻居数（MinPts）</strong>；<strong>半径参数（eps）</strong></p>
<p>对每个数据点，DBSCAN通过检查它在半径（eps）范围内的邻居数是否达到最小邻居数（&gt;&#x3D;MinPts）来判断这一数据点是否为核心点。</p>
<ul>
<li>&gt;&#x3D;MinPts 则为核心点；&lt;MinPts则为噪声点。</li>
</ul>
<h5 id="优缺点："><a href="#优缺点：" class="headerlink" title="优缺点："></a>优缺点：</h5><img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/23.png" class="" title="图片描述">

<h3 id="3、异常值的处理"><a href="#3、异常值的处理" class="headerlink" title="3、异常值的处理"></a>3、异常值的处理</h3><ul>
<li><strong>直接删除</strong></li>
<li>**异常值替换：**均值替换；中位数替换；截断（超过异常值边界的值用边界值代替）</li>
<li>**异常值修正：**对数变化（减少右偏分布的影响）；平方根变换（适用于轻微偏移的数据）；Box-Cox变换（通过参数调整数据分布，使其更接近正态分布）</li>
<li><strong>分离异常值单独分析</strong></li>
</ul>
<h5 id="异常值处理的影响评估："><a href="#异常值处理的影响评估：" class="headerlink" title="异常值处理的影响评估："></a>异常值处理的影响评估：</h5><ul>
<li><strong>可视化图表</strong>（直方图；QQ图——验证正态性）</li>
<li><strong>统计量量化</strong>（均值，方差，偏度的变化）</li>
<li><strong>模型性能的前后验证</strong>：如线性回归模型的R2变化；k - means聚类的轮廓系数变化</li>
</ul>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E7%AC%94%E8%AE%B0/" style="color: #ffa2c4">笔记</a>
        </span>
        
    </div>
    <a href="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">
        <h2 class="post-title">大数据探索性分析课程笔记</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                复习笔记
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/12/9
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="数据配平"><a href="#数据配平" class="headerlink" title="数据配平"></a>数据配平</h2><h3 id="一、数据配平定义"><a href="#一、数据配平定义" class="headerlink" title="一、数据配平定义"></a>一、数据配平定义</h3><p>数据配平是针对于机器学习中“类别不平衡”问题的关键预处理技术，通过调整不同类别的样本分布比例，使模型能够提升对少数类样本的识别能力。</p>
<p>例如：想象你要训练一个 “识别人” 的模型：如果给它 1000 张男生照片、只给 1 张女生照片，模型练完后大概率只会认男生 —— 因为它见太多男生、没学过女生的特征，这就是 “类别不平衡”。</p>
<h5 id="类别不平衡的危害："><a href="#类别不平衡的危害：" class="headerlink" title="类别不平衡的危害："></a>类别不平衡的危害：</h5><ul>
<li>模型对于少数类的预测能力较差</li>
<li>在不平衡数据集上，常用的准确率指标可能误导分析</li>
<li>实际场景中漏检关键少数类</li>
</ul>
<h3 id="二、欠采样-删"><a href="#二、欠采样-删" class="headerlink" title="二、欠采样 - 删"></a>二、欠采样 - 删</h3><h5 id="定义：通过减少多数类样本的样本数量来平衡数据集"><a href="#定义：通过减少多数类样本的样本数量来平衡数据集" class="headerlink" title="定义：通过减少多数类样本的样本数量来平衡数据集"></a>定义：通过减少多数类样本的样本数量来平衡数据集</h5><ul>
<li>随机欠采样：随机删除多数类样本，使两类样本数量接近</li>
<li>基于聚类的欠采样：对多数类样本聚类（K - means），仅保留簇中心样本</li>
</ul>
<p>注：这里K - means聚类就是将多数类分为多个簇，每个簇保留中心样本</p>
<h5 id="欠采样的缺点"><a href="#欠采样的缺点" class="headerlink" title="欠采样的缺点"></a>欠采样的缺点</h5><p>删去样本可能会丢失有价值的信息；同时数据量的减少还会导致模型泛化能力下降</p>
<h5 id="解决欠采样导致的信息缺失方法："><a href="#解决欠采样导致的信息缺失方法：" class="headerlink" title="解决欠采样导致的信息缺失方法："></a>解决欠采样导致的信息缺失方法：</h5><ul>
<li><p>Bagging法：对多数类进行多次有放回的欠采样，从而得到多个不同的训练集，对这些不同训练集建立模型（也叫训练出多个分类器），最后综合得到的结果。</p>
<p>即：多次有放回欠采样，多模型组合</p>
</li>
<li><p>Boosting法：先通过一次欠采样得到训练集，并建立模型训练出一个分类器；然后从一开始的样本集中删掉第一次用掉的这些样本，对剩下的样本再次欠采样重复上面的步骤，最后综合得到结果。</p>
<p>即：逐步删除已经学会的多数类样本，多模型迭代</p>
</li>
</ul>
<h3 id="三、过采样-补"><a href="#三、过采样-补" class="headerlink" title="三、过采样 - 补"></a>三、过采样 - 补</h3><h5 id="定义：增加少数类样本数量来平衡数据集"><a href="#定义：增加少数类样本数量来平衡数据集" class="headerlink" title="定义：增加少数类样本数量来平衡数据集"></a>定义：增加少数类样本数量来平衡数据集</h5><ul>
<li><p>随机过采样：直接复制少数类样本（比如把 100 个少数类复制 9 次变 1000 个）</p>
<ul>
<li>优点：简单快速</li>
<li>缺点：导致样本重复，使模型在新数据上泛化能力差</li>
</ul>
</li>
<li><p>SMOTE方法：仿照少数类样本，造与他们相似的新样本</p>
<ul>
<li>优点：样本多样</li>
<li>缺点：可能偏离真实数据分布</li>
</ul>
</li>
</ul>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/1.png" class="" title="图片描述">

<h3 id="四、加权损失函数"><a href="#四、加权损失函数" class="headerlink" title="四、加权损失函数"></a>四、加权损失函数</h3><p>解释：对少数类样本赋予更大的权重</p>
<p>优：不引入新样本，不改变数据分布，模型保持原有结构</p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>模型预测值和真实值的差</p>
<h2 id="五、对模型的评估和优化"><a href="#五、对模型的评估和优化" class="headerlink" title="五、对模型的评估和优化"></a>五、对模型的评估和优化</h2><p>如何判断分类模型好不好？（特别是当样本不均衡的时候）</p>
<h3 id="1）混淆矩阵"><a href="#1）混淆矩阵" class="headerlink" title="1）混淆矩阵"></a>1）混淆矩阵</h3><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/4.png" class="" title="图片描述">

<p>总结：</p>
<p>情境：二分类问题，所有样本为两类之一：正例、负例</p>
<ul>
<li>TP：真实值为正例；预测值为正例 —— 预测正确</li>
<li>FP：真实值为负例；预测值为正例 —— 将多数样本判为少数样本（误报）</li>
<li>FN：真实值为正例；预测值为负例 —— 漏掉少数样本（漏报）</li>
<li>TN：真实值为负例；预测值为负例 —— 预测正确</li>
</ul>
<h3 id="2）准确率"><a href="#2）准确率" class="headerlink" title="2）准确率"></a>2）准确率</h3><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/5.png" class="" title="图片描述">

<p>即：混淆矩阵（左上+右下）&#x2F;（总样本数）</p>
<h3 id="3）精准率"><a href="#3）精准率" class="headerlink" title="3）精准率"></a>3）精准率</h3><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/6.png" class="" title="图片描述">

<p>即：混淆矩阵（左上）&#x2F;（左上+左下）</p>
<p>注：误报（FP）（左下）成本高的场景，追求高精准率</p>
<h3 id="4）召回率"><a href="#4）召回率" class="headerlink" title="4）召回率"></a>4）召回率</h3><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/7.png" class="" title="图片描述">

<p>即：混淆矩阵（左上）&#x2F;（左上+右上）</p>
<p>注：漏报（FN）（右上）成本高的场景，追求高召回率</p>
<h3 id="5）F1得分-兼顾精准率与召回率"><a href="#5）F1得分-兼顾精准率与召回率" class="headerlink" title="5）F1得分 - 兼顾精准率与召回率"></a>5）F1得分 - 兼顾精准率与召回率</h3><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/8.png" class="" title="图片描述">

<h3 id="6）ROC曲线"><a href="#6）ROC曲线" class="headerlink" title="6）ROC曲线"></a>6）ROC曲线</h3><h5 id="分类阈值"><a href="#分类阈值" class="headerlink" title="分类阈值"></a>分类阈值</h5><p>模型的分类结果依赖于一个分类阈值，如：结果为正例的概率超过0.5就预测为正例。</p>
<h4 id="ROC曲线的两个指标"><a href="#ROC曲线的两个指标" class="headerlink" title="ROC曲线的两个指标"></a>ROC曲线的两个指标</h4><ul>
<li>TPR（True Positive Rate）&#x3D; 召回率 &#x3D; 混淆矩阵（左上）&#x2F;（左上+右上）</li>
<li>FPR（False Positive Rate）（误报率）&#x3D; 混淆矩阵（左下）&#x2F;（左下+右下）</li>
</ul>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/10.png" class="" title="图片描述">

<h4 id="ROC曲线画图"><a href="#ROC曲线画图" class="headerlink" title="ROC曲线画图"></a>ROC曲线画图</h4><p>ROC曲线是一条以FPR为横坐标，TPR为纵坐标的曲线。</p>
<p>即：通过不断调整模型的分类阈值，会得到一系列（FPR，TPR）的点，这些点组成了ROC曲线。</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/9.png" class="" title="图片描述">

<ul>
<li>模型分类阈值高时，靠近左下（0，0）</li>
<li>模型分类阈值低时，靠近右上（1，1）</li>
</ul>
<p>好的二分类模型的ROC曲线应该急剧向上凸，快速接近左上角（即：当FPR低的时候就有高的TPR）</p>
<h4 id="AUC：ROC曲线下面部分的面积"><a href="#AUC：ROC曲线下面部分的面积" class="headerlink" title="AUC：ROC曲线下面部分的面积"></a>AUC：ROC曲线下面部分的面积</h4><p>作用：用于衡量分类器的性能</p>
<ul>
<li>AUC &#x3D; 1：完美分类器</li>
<li>AUC &#x3D; 0.5：随机猜测模型（模型没有任何区分能力）</li>
<li>AUC &lt; 0.5：无效模型</li>
</ul>
<h2 id="特征变换"><a href="#特征变换" class="headerlink" title="特征变换"></a>特征变换</h2><h3 id="一、特征变换定义："><a href="#一、特征变换定义：" class="headerlink" title="一、特征变换定义："></a>一、特征变换定义：</h3><p>将原始数据中的特征转化为更适合模型使用的形式，通过改变特征分布或表现形式，但不改变信息本质。</p>
<h4 id="特征工程："><a href="#特征工程：" class="headerlink" title="特征工程："></a>特征工程：</h4><ul>
<li>特征变换：改变已有特征</li>
<li>特征选择：筛选出最重要的特征</li>
<li>特征提取：把多个特征浓缩为少数几个</li>
</ul>
<h5 id="为什么做特征变换："><a href="#为什么做特征变换：" class="headerlink" title="为什么做特征变换："></a>为什么做特征变换：</h5><ul>
<li>适应模型的尺度敏感性</li>
<li>解决数据分布失衡</li>
<li>建模非线性关系</li>
<li>处理非数值特征</li>
<li>提升建模收敛速度</li>
</ul>
<h3 id="二、解决尺度差异："><a href="#二、解决尺度差异：" class="headerlink" title="二、解决尺度差异："></a>二、解决尺度差异：</h3><h4 id="1）标准化"><a href="#1）标准化" class="headerlink" title="1）标准化"></a>1）标准化</h4><p>即：将原来所有特征全部统一改为 - 均值为0、标准差为1的统一标准</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/11.png" class="" title="图片描述">

<p>特点：不改变数据分布，只改变尺度和中心；对异常值敏感</p>
<h4 id="2）归一化"><a href="#2）归一化" class="headerlink" title="2）归一化"></a>2）归一化</h4><p>定义：将数据按比例压缩到一个固定范围</p>
<h5 id="Min-Max-Scaling（最小最大归一化）-常用"><a href="#Min-Max-Scaling（最小最大归一化）-常用" class="headerlink" title="Min-Max Scaling（最小最大归一化）- 常用"></a>Min-Max Scaling（最小最大归一化）- 常用</h5><p>将数据按比例压缩到 [0,1] 的范围</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/12.png" class="" title="图片描述">

<p>缺点：容易受极端值的影响，若数据中存在异常值，归一化后的数据分布可能不均匀</p>
<p>当存在异常值时用鲁棒缩放</p>
<h5 id="最大绝对值缩放"><a href="#最大绝对值缩放" class="headerlink" title="最大绝对值缩放"></a>最大绝对值缩放</h5><p>将数据按比例压缩到 [-1,1]</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/13.png" class="" title="图片描述">

<h5 id="鲁棒缩放（Robust-Scaling）-针对含异常值的数据"><a href="#鲁棒缩放（Robust-Scaling）-针对含异常值的数据" class="headerlink" title="鲁棒缩放（Robust Scaling）- 针对含异常值的数据"></a>鲁棒缩放（Robust Scaling）- 针对含异常值的数据</h5><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/14.png" class="" title="图片描述">

<p>这里 IQR 指的是四分位距：</p>
<p>简单说就是数据中 “中间 50% 的数的范围”—— 先把数据从小到大排序，取第 75% 位置的数（上四分位数 Q3）减去第 25% 位置的数（下四分位数 Q1），即 IQR &#x3D; Q3 - Q1。</p>
<h3 id="三、改善分布"><a href="#三、改善分布" class="headerlink" title="三、改善分布"></a>三、改善分布</h3><h5 id="1）对数变换-压缩数据尺度"><a href="#1）对数变换-压缩数据尺度" class="headerlink" title="1）对数变换 - 压缩数据尺度"></a>1）对数变换 - 压缩数据尺度</h5><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/15.png" class="" title="图片描述">

<h5 id="2）BOX-COX变换"><a href="#2）BOX-COX变换" class="headerlink" title="2）BOX - COX变换"></a>2）BOX - COX变换</h5><p>目标：将非正态分布数据转换为近似正态分布数据</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/16.png" class="" title="图片描述">

<h5 id="3）离散化-分箱"><a href="#3）离散化-分箱" class="headerlink" title="3）离散化 &#x3D; 分箱"></a>3）离散化 &#x3D; 分箱</h5><p>定义：将连续不断的数值特征划分为有限个区间；并将每个区间映射为一个离散值的过程</p>
<p>数据预处理阶段：</p>
<ul>
<li><p>**等宽分箱：**将值域范围划分为K个等宽的区间，宽度 &#x3D; （max - min）&#x2F;  K</p>
<ul>
<li>缺点：对异常值敏感；导致数据分布不均</li>
</ul>
</li>
<li><p>**等频分箱：**将数据划分为K个区间，使得每个区间包含样本数相同</p>
<ul>
<li>分界点选择：数据的分位数</li>
</ul>
</li>
<li><p>基于业务知识&#x2F;模型性能的分箱</p>
</li>
</ul>
<h5 id="4）离散化的作用："><a href="#4）离散化的作用：" class="headerlink" title="4）离散化的作用："></a>4）离散化的作用：</h5><ul>
<li>引入非线性关系</li>
<li>改善特征分布 - 将非正态分布的数据转化为(近)均匀分布</li>
<li>提高模型鲁棒性 - 限制离散值与噪声的影响</li>
<li>便于特征交叉与解释 - 特征组合</li>
</ul>
<h3 id="四、类别特征编码"><a href="#四、类别特征编码" class="headerlink" title="四、类别特征编码"></a>四、类别特征编码</h3><h4 id="1）独热编码（One-Hot-Encoding）"><a href="#1）独热编码（One-Hot-Encoding）" class="headerlink" title="1）独热编码（One - Hot Encoding）"></a>1）独热编码（One - Hot Encoding）</h4><p>定义：为每个类别建二值列，样本属于该类别则列值为 1，否则为 0</p>
<p>人话：将类别型特征变为模型能读懂的数字形式，通过给每个类别单独建一列，样本属于哪个类别，对应列标“1”，其他列标“0”</p>
<p>案例：</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/17.png" class="" title="图片描述">

<p>特点：</p>
<ul>
<li>平等对待所有类别</li>
<li>缺点1：类别数量多时，会增加数据集维度</li>
<li>缺点2：多重共线性（比如 3 个类别列的和永远是 1（因为一个样本只能属于一个类别），会让模型计算出问题）<ul>
<li>解决方法：哑变量编码（去掉其中一列，这一列代表类别用其他列表示）</li>
</ul>
</li>
<li>缺点3：特征重要性分散</li>
</ul>
<h4 id="2）序数编码"><a href="#2）序数编码" class="headerlink" title="2）序数编码"></a>2）序数编码</h4><p>定义：处理”有顺序的类别特征“，把有序类别（如小学→中学→大学）映射成有序整数（1→2→3），保留类别间的顺序关系。</p>
<p>优点：</p>
<ul>
<li>保留顺序信息</li>
<li>避免维度爆炸</li>
</ul>
<p>缺点：</p>
<ul>
<li>隐含”数值距离相等“假设</li>
<li>类别数量多时，过度关注数值大小，忽略类别本身意义</li>
<li>测试集可能出现新类别<ul>
<li>预先定义完整的类别顺序</li>
<li>制定规则处理未知类别</li>
</ul>
</li>
</ul>
<h4 id="3）频率编码"><a href="#3）频率编码" class="headerlink" title="3）频率编码"></a>3）频率编码</h4><p>定义：将分类变量替换为它在数据集中出现的频率</p>
<p>注：频率本身带有预测信息，如：比如 “Chrome 浏览器” 出现频率高，说明它是主流浏览器，可能对应 “年轻用户” 等特征，模型能利用这种 “常见程度” 的信号</p>
<p>适用场景：类别出现频率本身具有信息量时</p>
<p>缺点：丢失类别本身的信息（如果两个不同类别出现频率一样（比如 “Firefox” 和 “Edge” 都出现 200 次，编码都是 0.2），模型会把它们当成同一个特征）</p>
<p>注：只能在训练集上计算频率，防止数据泄露</p>
<h4 id="4）目标编码"><a href="#4）目标编码" class="headerlink" title="4）目标编码"></a>4）目标编码</h4><p>定义：用“类别对应的目标变量统计值”代替类别标签</p>
<p>如：比如预测 “用户是否购买商品”（目标是 “购买 &#x2F; 不购买”），对 “城市” 这个类别特征，计算每个城市的 “购买率”（目标变量的期望值），用这个购买率作为该城市的编码值。</p>
<p>优点：</p>
<ul>
<li>直接编码类别与目标变量之间的统计关系，为模型提供了强烈的预测信号</li>
<li>编码值具有明确的业务含义</li>
</ul>
<p>适用条件：需要足够样本量支撑</p>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><h3 id="一、维数灾难-过多特征"><a href="#一、维数灾难-过多特征" class="headerlink" title="一、维数灾难 - 过多特征"></a>一、维数灾难 - 过多特征</h3><p>维数的定义：数据集中特征的数量</p>
<p>维数灾难的定义：随着数据维度增加，数据分析和建模变得复杂和低效的现象</p>
<p>随着维度的增加会带来的表现：</p>
<ul>
<li>样本空间的稀疏性：高纬度空间里面数据点分散</li>
<li>高维球体中，数据分布集中在表面</li>
<li>距离度量失效：如欧式距离无法区分样本</li>
<li>特征相关和冗余：维数增加，特征变得高度相关和冗余，增加计算复杂性</li>
<li>计算复杂度增加</li>
<li>过拟合：高维数据特征数量远多于样本数量时，模型容易过拟合</li>
</ul>
<h4 id="特征选择-1"><a href="#特征选择-1" class="headerlink" title="特征选择"></a>特征选择</h4><h5 id="定义：从原始特征集合中筛选出与目标变量高度相关、冗余度低的特征子集，保留对模型最有价值的信息"><a href="#定义：从原始特征集合中筛选出与目标变量高度相关、冗余度低的特征子集，保留对模型最有价值的信息" class="headerlink" title="定义：从原始特征集合中筛选出与目标变量高度相关、冗余度低的特征子集，保留对模型最有价值的信息"></a>定义：从原始特征集合中筛选出与目标变量高度相关、冗余度低的特征子集，保留对模型最有价值的信息</h5><p>特征选择的方法：</p>
<ul>
<li><strong>过滤法</strong>：只看特征的【统计特性】，和模型训练没关系（独立于模型）</li>
<li><strong>封装法</strong>：用模型性能作为特征选择的评估标准，通过反复训练模型来筛选特征</li>
<li><strong>嵌入法</strong>：特征选择和模型训练“绑在一起”，通过模型给出的“特征重要性”来选择特征</li>
</ul>
<h3 id="二、过滤法"><a href="#二、过滤法" class="headerlink" title="二、过滤法"></a>二、过滤法</h3><p>定义：基于特征的统计特性进行特征选择，独立于机器学习算法</p>
<p>适用场景：大规模数据初步筛选</p>
<h5 id="过滤法会筛选掉哪些数据："><a href="#过滤法会筛选掉哪些数据：" class="headerlink" title="过滤法会筛选掉哪些数据："></a>过滤法会筛选掉哪些数据：</h5><ul>
<li><u>冗余</u>或<u>与目标不相关</u>的特征</li>
<li><u>方差较低</u>的特征</li>
<li><u>取值几乎不变</u>的特征</li>
<li><u>强相关</u>的特征：计算所有特征间的相关系数，删除和其他特征平均相似度更【高】的特征，重复，直到任何两个特征之间的相关系数低于某个临界值</li>
<li>特征进行<u>聚类</u>：从每一类选少数几个有代表性的特征</li>
</ul>
<h4 id="1）相关系数法"><a href="#1）相关系数法" class="headerlink" title="1）相关系数法"></a>1）相关系数法</h4><h5 id="皮尔逊相关系数（SIS）-两个数值型变量的线性相关程度"><a href="#皮尔逊相关系数（SIS）-两个数值型变量的线性相关程度" class="headerlink" title="皮尔逊相关系数（SIS）- 两个数值型变量的线性相关程度"></a>皮尔逊相关系数（SIS）- 两个数值型变量的线性相关程度</h5><p>通过衡量每个特征与目标变量的皮尔逊相关系数来衡量它们之间的重要性</p>
<p>作用：衡量“特征与目标变量”的线性关系强度，从而筛选无关特征</p>
<p>适用场景：【数值型特征】的【线性关系】评估</p>
<p>注：皮尔逊相关系数只能捕捉【线性关系】，无法识别特征与目标间的非线性关系</p>
<h5 id="补充：皮尔逊相关系数的计算"><a href="#补充：皮尔逊相关系数的计算" class="headerlink" title="补充：皮尔逊相关系数的计算"></a>补充：皮尔逊相关系数的计算</h5><p>核心：衡量两个数值型变量（”特征X“和”目标Y“）的线性相关程度</p>
<p>样本数：n</p>
<p>特征X取值：<em>x</em>1,<em>x</em>2,…,<em>x</em>n</p>
<p>特征Y取值：<em>y</em>1,<em>y</em>2,…,<em>y</em>n</p>
<ul>
<li><p>计算X和Y的平均值</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/18.png" class="" title="图片描述">
</li>
<li><p>计算“偏差乘积和”</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/19.png" class="" title="图片描述">
</li>
<li><p>分别计算X和Y的”偏差平方和的平方根“</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/20.png" class="" title="图片描述">
</li>
<li><p>皮尔逊相关系数计算</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/21.png" class="" title="图片描述">

<ul>
<li>r 的取值范围：[-1,1]<ul>
<li>靠近 1：XY正线性相关</li>
<li>靠近 -1：XY负线性相关</li>
<li>靠近 0：XY线性无关</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2）卡方检验-两个离散型变量之间的独立性"><a href="#2）卡方检验-两个离散型变量之间的独立性" class="headerlink" title="2）卡方检验 - 两个离散型变量之间的独立性"></a>2）卡方检验 - 两个离散型变量之间的独立性</h4><p>卡方检验用于判断”离散型特征和离散型目标变量“之间的独立性</p>
<p>通过案例来解释：</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/22.png" class="" title="图片描述">

<p>核心步骤：</p>
<ul>
<li><p>提出【原假设】和【备择假设】</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/23.png" class="" title="图片描述">
</li>
<li><p>构造列联表，统计观测频数：<em>O</em>i</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/24.png" class="" title="图片描述">
</li>
<li><p>计算期望频数：<em>E</em>i</p>
<p>计算公式：</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/26.png" class="" title="图片描述">

<p>案例：</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/25.png" class="" title="图片描述">

<p>计算出结果：</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/27.png" class="" title="图片描述">
</li>
<li><p>计算卡方统计量：<em>χ</em>2</p>
<p>对每个单元格，算 “（观测频数 - 期望频数）的平方 ÷ 期望频数”，再把所有结果加起来，得到卡方值</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/28.png" class="" title="图片描述">
</li>
<li><p>假设检验</p>
<p>卡方值越大，越拒绝 “两者独立” 的原假设，认为特征与目标相关</p>
<ul>
<li><p>确定原假设（<em>H</em>0）：支付方式与评分是独立的（没关系）</p>
</li>
<li><p>卡方统计量：<em>χ</em>2&#x3D;152.36</p>
</li>
<li><p>确定【自由度】</p>
<ul>
<li>公式：自由度 &#x3D;（行数 - 1）*（列数 - 1）</li>
</ul>
</li>
<li><p>确定【显著性水平】</p>
<ul>
<li><p>定义：有多少概率错误地推翻原假设</p>
</li>
<li><p><em>α</em>&#x3D;0.05（意思是：有 5% 的概率错误地推翻原假设）</p>
</li>
</ul>
</li>
<li><p>查表</p>
<ul>
<li>找：“自由度 &#x3D; 12，显著性水平 &#x3D; 0.05” 对应的<strong>临界值</strong></li>
<li>查出来是 21.03</li>
</ul>
</li>
<li><p>得出结论：</p>
<ul>
<li>案例中计算的卡方统计量是 152.36，远大于临界值 21.03</li>
<li>当 “卡方统计量&gt; 临界值” 时，说明 “实际与期望的差距太大，原假设（没关系）站不住脚”，因此<strong>拒绝原假设，接受备择假设</strong>—— 认为 “支付方式与评分显著相关”</li>
</ul>
</li>
</ul>
</li>
<li><p>总结：</p>
<ul>
<li>算出来的卡方越大，特征与目标的关联性越强</li>
<li>相应的卡方对应的p值（假设检验的显著性值）越小，特征越重要</li>
</ul>
</li>
</ul>
<h4 id="3）单变量方差分析（One-Way-ANOVA）-检测离散特征（分类变量）对数值型目标变量（连续变量）的影响是否显著-检验数值型特征和离散型目标变量的显著性"><a href="#3）单变量方差分析（One-Way-ANOVA）-检测离散特征（分类变量）对数值型目标变量（连续变量）的影响是否显著-检验数值型特征和离散型目标变量的显著性" class="headerlink" title="3）单变量方差分析（One-Way ANOVA）- 检测离散特征（分类变量）对数值型目标变量（连续变量）的影响是否显著 &#x2F; 检验数值型特征和离散型目标变量的显著性"></a>3）单变量方差分析（One-Way ANOVA）- 检测离散特征（分类变量）对数值型目标变量（连续变量）的影响是否显著 &#x2F; 检验数值型特征和离散型目标变量的显著性</h4><p>通过案例了解：</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/29.png" class="" title="图片描述">

<p>解答步骤：</p>
<ul>
<li><p>提出原假设</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/30.png" class="" title="图片描述">
</li>
<li><p>计算总平均购买均值 （总均值）</p>
</li>
<li><p>按用户等级分组，计算每组的组内平均金额（组内均值）</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/31.png" class="" title="图片描述">
</li>
<li><p>计算【组间平方和 SSB】和【组间均方 MSB】</p>
</li>
<li><p>计算【组内平方和 SSW】和【组内均方 MSW】</p>
</li>
<li><p>计算【统计量 F】&#x3D; 组间均方 &#x2F; 组内均方</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/32.png" class="" title="图片描述">

<ul>
<li>F值越大，相关性越高，组间差异越显著，越推翻原假设，认为特征对目标有显著影响</li>
</ul>
</li>
<li><p>通过p值下结论</p>
<ul>
<li>p值为”原假设成立的概率“，p值太小（&lt; 0.05），推翻原假设，认为用户等级对购买金额有显著影响</li>
</ul>
</li>
</ul>
<p>例（SSB和SSW的计算）：</p>
<p>案例：</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/33.png" class="" title="图片描述">

<p>SSB 组间平方和：</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/34.png" class="" title="图片描述">

<p>SSW 组内平方和：</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/35.png" class="" title="图片描述">

<ul>
<li><p>总结</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/36.png" class="" title="图片描述"></li>
</ul>
<p>三、封装法</p>
<p>四、嵌入法</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E7%AC%94%E8%AE%B0/" style="color: #ffa2c4">笔记</a>
        </span>
        
    </div>
    <a href="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/" class="go-post">阅读全文</a>
</div>


        <div class="page-current">
    
    <span class="current">1</span>
    
    <a class="page-num" href="/page/2">
        2
    </a>
    
    
    <a class="page-num" href="/page/3">
        3
    </a>
    
    
    
    <a class="page-num" href="/page/2/">
        <i class="fa-solid fa-caret-right fa-fw"></i>
    </a>
    
</div>

    </div>
    
    <div id="home-card">
        <div id="card-style">
    <div id="card-div">
        <div class="avatar">
            <img src="/images/xnylh.webp" alt="avatar" />
        </div>
        <div class="name">Leo yu yty</div>
        <div class="description">
            <p>yty的个人博客~<br>分享日常和学习心得</p>

        </div>
        
        
        <div class="friend-links">
            
            <div class="friend-link">
                <a target="_blank" rel="noopener" href="https://argvchs.github.io">Argvchs</a>
            </div>
            
            <div class="friend-link">
                <a target="_blank" rel="noopener" href="https://blog.csdn.net/leo_yty?spm=1000.2692.3001.5343">yty的csdn博客</a>
            </div>
            
        </div>
        
    </div>
</div>

    </div>
    
</div>

            <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2005 - 2025 yty的博客
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;Leo yu yty
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

        </div>
        
        <transition name="fade">
            <div id="preview" ref="preview" v-show="previewShow">
                <img id="preview-content" ref="previewContent" />
            </div>
        </transition>
        
    </div>
    <script src="/js/main.js"></script>
    
</body>
</html>
