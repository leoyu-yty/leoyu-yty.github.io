
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8" />
    <title>yty的博客</title>
    <meta name="author" content="Leo yu yty" />
    <meta name="description" content="Hello Everyone This is my website" />
    <meta name="keywords" content="" />
    <meta
        name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"
    />
    <link rel="icon" href="/images/xnylh.webp" />
    <link rel="preconnect" href="https://s4.zstatic.net" />
<script src="https://s4.zstatic.net/ajax/libs/vue/3.3.7/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
<link rel="preconnect" href="https://fonts.googleapis.cn" />
<link rel="preconnect" href="https://fonts.gstatic.cn" crossorigin />
<link
    rel="stylesheet"
    href="https://fonts.googleapis.cn/css2?family=Fira+Code:wght@400;500;600;700&family=Lexend:wght@400;500;600;700;800;900&family=Noto+Sans+SC:wght@400;500;600;700;800;900&display=swap"
/>
<script> const mixins = {}; </script>

<script src="https://polyfill.alicdn.com/v3/polyfill.min.js?features=default"></script>


<script src="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<link
    rel="stylesheet"
    href="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>



<script src="/js/lib/preview.js"></script>





<script src="/js/lib/home.js"></script>

<link rel="stylesheet" href="/css/main.css" />

<meta name="generator" content="Hexo 8.1.1"></head>
<body>
    <div id="layout">
        <transition name="fade">
            <div id="loading" v-show="loading">
                <div id="loading-circle">
                    <h2>LOADING</h2>
                    <p>加载过慢请开启缓存 浏览器默认开启</p>
                    <img src="/images/loading.gif" />
                </div>
            </div>
        </transition>
        <div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <nav id="desktop-menu">
        <a class="title" href="/">
            <span>YTY的博客</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;主页</span>
        </a>
        
        <a href="/about/">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;关于</span>
        </a>
        
        <a href="/archives/">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;文章</span>
        </a>
        
        <a href="/categories/">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;分类</span>
        </a>
        
        <a href="/tags/">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;标签</span>
        </a>
        
    </nav>
    <nav id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;YTY的博客</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">主页</div>
                    </div>
                </a>
                
                <a href="/about/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">关于</div>
                    </div>
                </a>
                
                <a href="/archives/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">文章</div>
                    </div>
                </a>
                
                <a href="/categories/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">分类</div>
                    </div>
                </a>
                
                <a href="/tags/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">标签</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </nav>
</div>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

        <div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'">
            <div id="home-head">
    <div
        id="home-background"
        ref="homeBackground"
        data-images="/images/science.jpg"
    ></div>
    <div id="home-info" @click="homeClick">
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="info">
            <div class="wrap">
                <h1>yty的博客</h1>
                <h3>yty的日常博客记录</h3>
                <h5>Hello Everyone This is my website</h5>
            </div>
        </span>
    </div>
</div>
<div
    id="home-posts-wrap"
    ref="homePostsWrap"
    true
>
    <div id="home-posts">
        

<div class="post">
    <a href="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/">
        <h2 class="post-title">大数据探索分析课程基础</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                复习笔记
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/12/10
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="大数据探索性分析基本流程"><a href="#大数据探索性分析基本流程" class="headerlink" title="大数据探索性分析基本流程"></a>大数据探索性分析基本流程</h2><p>**1）理解数据：**了解数据的结构、质量（缺失值、错误值、重复值）、分布（数据取值范围、集中趋势 - 均值&#x2F;中位数、离散程度 - 方差&#x2F;标准差）等规律</p>
<p>**2）发现线索：**识别趋势、异常值、关联</p>
<p>**3）形成假设：**针对线索，生成可验证的假设</p>
<p>**4）检查前提：**有很多数据分析模型（如：回归分析，方差分析）都有明确的适用前提，如：正态性（数据分布符合正态分布）、独立性（样本之间无关联）</p>
<p>**5）建模准备：**包括数据清洗、特征工程（标准化&#x2F;归一化）</p>
<h2 id="一、数据形式内容"><a href="#一、数据形式内容" class="headerlink" title="一、数据形式内容"></a>一、数据形式内容</h2><h4 id="数据的形式（偏概念）"><a href="#数据的形式（偏概念）" class="headerlink" title="数据的形式（偏概念）"></a>数据的形式（偏概念）</h4><p>**1）结构化数据：**以行和列存储，具有固定格式和明确字段含义的数据（便于计算机直接读取的数据）</p>
<p>**核心分析方法：**SQL查询、回归分析（线性回归预测连续型变量；逻辑回归预测分类型变量）</p>
<p>**2）非结构化数据：**无固定格式的数据，需要通过半结构化处理才能被分析的数据</p>
<p>**核心分析方法：**自然语言处理、计算机视觉、语音识别</p>
<p>**数据元素的类型：**数值型、字符型、布尔值、日期时间型、列表型、字典型</p>
<p>**属性的类型：**类别型、序数型、区间型、比率型</p>
<h4 id="数据点的相似性度量"><a href="#数据点的相似性度量" class="headerlink" title="数据点的相似性度量"></a>数据点的相似性度量</h4><h5 id="纯数值型属性情况："><a href="#纯数值型属性情况：" class="headerlink" title="纯数值型属性情况："></a>纯数值型属性情况：</h5><img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/1.png" class="" title="图片描述">

<h5 id="纯类别型属性情况："><a href="#纯类别型属性情况：" class="headerlink" title="纯类别型属性情况："></a>纯类别型属性情况：</h5><img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/2.png" class="" title="图片描述">

<p>简单匹配系数方法适用于有重复类别的情况；Jaccard系数方法适用于无重复类别的情况</p>
<p>简单匹配系数案例：</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/24.png" class="" title="图片描述">

<h5 id="纯序数型属性情况："><a href="#纯序数型属性情况：" class="headerlink" title="纯序数型属性情况："></a>纯序数型属性情况：</h5><img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/3.png" class="" title="图片描述">

<h5 id="混合型属性情况："><a href="#混合型属性情况：" class="headerlink" title="混合型属性情况："></a>混合型属性情况：</h5><p>案例：</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/4.png" class="" title="图片描述">

<p>解答：</p>
<p>目标：比较A与B像不像</p>
<p><strong>step 1：计算每个属性的局部距离（不像程度）</strong></p>
<p><strong>1）年龄（数值属性）</strong></p>
<p>局部距离 &#x3D; A(35)与B(28)年龄差 &#x2F; 年龄最大范围差 （这里年龄最大范围假设为18 - 70，差为52) &#x3D; 0.135</p>
<p><strong>2）性别（二元属性）</strong></p>
<p>二人不同性别，局部距离 &#x3D; 1</p>
<p><strong>3）教育程度（序数属性）</strong></p>
<p>把学历按 “高中 &#x3D; 1、学士 &#x3D; 2、硕士 &#x3D; 3、博士 &#x3D; 4” 排顺序</p>
<p>局部距离 &#x3D; A(3)与B(2)的差 &#x2F; 学历最大范围差(4-1&#x3D;3) &#x3D; 0.333</p>
<p><strong>4）购买类别（类别属性）</strong></p>
<p>由于二者完全没有重叠部分，采用Jaccard方法计算</p>
<p>局部距离 &#x3D; 1-(重叠数&#x2F;总类别数) &#x3D; 1</p>
<p><strong>总结一下这部分：</strong></p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/5.png" class="" title="图片描述">

<p><strong>step 2：设置权重，计算加权距离（加权距离为：对应属性权重 * 对应局部距离）</strong></p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/6.png" class="" title="图片描述">

<p>—— 0表示完全相同，1表示完全不同。</p>
<h2 id="二、描述型统计"><a href="#二、描述型统计" class="headerlink" title="二、描述型统计"></a>二、描述型统计</h2><h4 id="集中趋势概念：均值、中位数、众数"><a href="#集中趋势概念：均值、中位数、众数" class="headerlink" title="集中趋势概念：均值、中位数、众数"></a>集中趋势概念：均值、中位数、众数</h4><img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/7.png" class="" title="图片描述">

<h4 id="离散程度："><a href="#离散程度：" class="headerlink" title="离散程度："></a>离散程度：</h4><p><strong>1）标准差</strong></p>
<p>**2）变异系数：**消除测量尺度和量纲的影响</p>
<p>如：身高用厘米、体重用公斤，单位不一样没法直接比波动？这时候用变异系数：把标准差除以平均值，去掉单位影响。</p>
<p>**3）极差：**最大数-最小数</p>
<p>**4）四分位差：**先把数据排好队，分成 4 等份，取中间那一半的范围（第 3 份减第 1 份）。不管两头的极端值，只看中间大多数数据的波动。</p>
<h4 id="分布形态：偏度、峰度"><a href="#分布形态：偏度、峰度" class="headerlink" title="分布形态：偏度、峰度"></a>分布形态：偏度、峰度</h4><p><strong>1）偏度</strong>（衡量数据偏移程度）- 偏不偏？</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/8.png" class="" title="图片描述">

<p><strong>2）峰度</strong>（衡量数据集中趋势的指标）- 尖不尖？</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/9.png" class="" title="图片描述">

<p>偏度是绝对指标、峰度是相对指标</p>
<h5 id="Q1：如何计算样本偏度和峰度？"><a href="#Q1：如何计算样本偏度和峰度？" class="headerlink" title="Q1：如何计算样本偏度和峰度？"></a>Q1：如何计算样本偏度和峰度？</h5><p><strong>1）计算样本偏度</strong></p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/10.png" class="" title="图片描述">

<p>样本偏度公式：</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/11.png" class="" title="图片描述">

<p><strong>2）计算样本峰度</strong></p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/12.png" class="" title="图片描述">

<h5 id="Q2：方差、偏度、峰度的联系？"><a href="#Q2：方差、偏度、峰度的联系？" class="headerlink" title="Q2：方差、偏度、峰度的联系？"></a>Q2：方差、偏度、峰度的联系？</h5><p>都是描述数据分布特征的指标</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/13.png" class="" title="图片描述">

<h2 id="三、属性类型与统计方法的适配"><a href="#三、属性类型与统计方法的适配" class="headerlink" title="三、属性类型与统计方法的适配"></a>三、属性类型与统计方法的适配</h2><h4 id="1）类别型属性"><a href="#1）类别型属性" class="headerlink" title="1）类别型属性"></a>1）类别型属性</h4><ul>
<li>核心统计方法：<br>- 频数：某类别的出现次数<br>- 频率：某类别出现次数占总数的比例</li>
<li>图表：柱状图、饼图</li>
</ul>
<h4 id="2）序数型属性（数据有顺序-等级，但没有固定的数值间隔）"><a href="#2）序数型属性（数据有顺序-等级，但没有固定的数值间隔）" class="headerlink" title="2）序数型属性（数据有顺序&#x2F;等级，但没有固定的数值间隔）"></a>2）序数型属性（数据有顺序&#x2F;等级，但没有固定的数值间隔）</h4><ul>
<li>核心统计方法：<br>- 累积频数：从低到高（或高到低）累加的次数（比如 “优 + 良” 的累积频数 &#x3D; 优的频数 + 良的频数）<br>- 等级相关分析：看两个序数数据的 “顺序关联”（比如 “成绩等级” 和 “作业完成等级” 是否正相关）</li>
</ul>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/14.png" class="" title="图片描述">

<ul>
<li>图表：折线图、箱线图</li>
</ul>
<h4 id="3）区间型属性"><a href="#3）区间型属性" class="headerlink" title="3）区间型属性"></a>3）区间型属性</h4><ul>
<li>核心统计方法：均值、方差</li>
<li>图表：直方图、散点图</li>
</ul>
<h4 id="4）比率型属性"><a href="#4）比率型属性" class="headerlink" title="4）比率型属性"></a>4）比率型属性</h4><ul>
<li>核心统计方法：均值、标准差、相关系数（看两个比率数据的 “线性关联强度”（比如 “身高” 和 “体重” 的相关程度））</li>
<li>图表：折线图、散点图</li>
</ul>
<h2 id="四、缺失值"><a href="#四、缺失值" class="headerlink" title="四、缺失值"></a>四、缺失值</h2><h4 id="1）缺失值的分类："><a href="#1）缺失值的分类：" class="headerlink" title="1）缺失值的分类："></a>1）缺失值的分类：</h4><ul>
<li>完全随机缺失：缺失与任何变量无关，仅由随机因素导致</li>
<li>随机缺失：缺失与已观测变量相关，但与缺失变量本身无关</li>
<li>非随机缺失：缺失与缺失变量本身直接相关</li>
</ul>
<h4 id="2）缺失数据的处理步骤"><a href="#2）缺失数据的处理步骤" class="headerlink" title="2）缺失数据的处理步骤"></a>2）缺失数据的处理步骤</h4><p>识别缺失值——探索缺失值的分布模式——分析导致缺失的原因——处理缺失值</p>
<h4 id="3）缺失值的处理"><a href="#3）缺失值的处理" class="headerlink" title="3）缺失值的处理"></a>3）缺失值的处理</h4><ul>
<li><strong>删除法：</strong><ul>
<li>行删除&amp;列删除</li>
</ul>
</li>
<li><strong>代表性性数据填充：</strong><ul>
<li>均值填充：适用于服从正态分布的数值型变量</li>
<li>中位数填充：适用于存在极端值的偏态分布</li>
<li>众数填充：适用于离散型分布变量</li>
<li>前向填充&#x2F;后向填充：适用于时间序列数据（如：今天的数字空了，就用明天的或者昨天的数据填充）</li>
</ul>
</li>
<li><strong>预测法填充：</strong><ul>
<li>回归填充：通过与缺失值有关联的变量建立回归模型，从而预测缺失值</li>
<li>KNN填充：找k个与缺失值相似情况的值，取他们的均值从而填充缺失值</li>
</ul>
</li>
</ul>
<h2 id="五、异常值（-离群点）"><a href="#五、异常值（-离群点）" class="headerlink" title="五、异常值（&#x3D; 离群点）"></a>五、异常值（&#x3D; 离群点）</h2><h3 id="1、概念部分"><a href="#1、概念部分" class="headerlink" title="1、概念部分"></a>1、概念部分</h3><h4 id="1）异常值的来源"><a href="#1）异常值的来源" class="headerlink" title="1）异常值的来源"></a>1）异常值的来源</h4><ul>
<li>数据来源于不同的类</li>
<li>自然变异</li>
<li>数据测量和收集误差</li>
<li>业务特征</li>
</ul>
<h4 id="2）异常值的类型"><a href="#2）异常值的类型" class="headerlink" title="2）异常值的类型"></a>2）异常值的类型</h4><ul>
<li>点异常值</li>
<li>上下文异常值</li>
<li>集体异常值</li>
</ul>
<h4 id="3）判断异常值需要注意"><a href="#3）判断异常值需要注意" class="headerlink" title="3）判断异常值需要注意"></a>3）判断异常值需要注意</h4><ul>
<li>确定数据对象是单一属性异常还是多个属性异常</li>
<li>异常值的全局观点和局部观点（数据是否异常需要考虑其所对比对象）</li>
<li>数据对象的异常程度</li>
<li>多个数据对象同时考虑看有没有异常</li>
</ul>
<h3 id="2、异常值检测"><a href="#2、异常值检测" class="headerlink" title="2、异常值检测"></a>2、异常值检测</h3><h4 id="1）基于统计方法检测异常值"><a href="#1）基于统计方法检测异常值" class="headerlink" title="1）基于统计方法检测异常值"></a>1）基于统计方法检测异常值</h4><h5 id="a、基于z-score的异常值检测"><a href="#a、基于z-score的异常值检测" class="headerlink" title="a、基于z-score的异常值检测"></a>a、基于z-score的异常值检测</h5><p>适用于：单变量+正态分布</p>
<p>z的值 &#x3D; （当前值 - 均值）&#x2F; 标准差</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/15.png" class="" title="图片描述">

<h5 id="b、基于箱线图的检测"><a href="#b、基于箱线图的检测" class="headerlink" title="b、基于箱线图的检测"></a>b、基于箱线图的检测</h5><p>箱线图（&#x3D; 盒须图）：由中位数Q2、下四分位数Q1、上四分位数Q3构成的箱体以及两个表示数据范围的须线组成，超出上下边缘的值为异常值。</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/16.png" class="" title="图片描述">

<h5 id="c、基于假设检验的检测"><a href="#c、基于假设检验的检测" class="headerlink" title="c、基于假设检验的检测"></a>c、基于假设检验的检测</h5><p>（适合数据少+只有一个异常值点+正态分布的情况）——（可以支持多变量）</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/17.png" class="" title="图片描述">

<p>用算出来的G，查表检验（G是否&gt;临界点）该值是否显著，若显著（&gt;），则该点为异常值点。</p>
<h4 id="2）基于局部离群因子检测异常值"><a href="#2）基于局部离群因子检测异常值" class="headerlink" title="2）基于局部离群因子检测异常值"></a>2）基于局部离群因子检测异常值</h4><h5 id="局部离群因子（LOF）"><a href="#局部离群因子（LOF）" class="headerlink" title="局部离群因子（LOF）"></a>局部离群因子（LOF）</h5><p>定义：通过评估数据对象相对于其局部邻近区域的离群程度来检测异常点，不是通过全局尺度来判定。</p>
<p>异常点位于局部密度较低的区域；正常点位于局部密度较高的区域。</p>
<p>LOF通过比较每个点的局部密度来判断该点是否为异常点。</p>
<ul>
<li><h5 id="计算局部离群因子（LOF）"><a href="#计算局部离群因子（LOF）" class="headerlink" title="计算局部离群因子（LOF）"></a>计算局部离群因子（LOF）</h5></li>
</ul>
<p><strong>step1：</strong></p>
<p>对数据集中每个点选取k个离他最近的点</p>
<p><strong>step2：</strong></p>
<p>计算k - 距离**（k - distance）&#x3D; 每个数据点p到与他的第k个最近点ok之间的距离**</p>
<p>ok又被称为点p的第k个最近邻</p>
<p>如：第五个点离该点2米，则k - 距离就为2米</p>
<p><strong>step3：</strong></p>
<p>定义<strong>可达距离</strong>（平滑点之间的距离，避免由于局部过于密集的区域导致的异常点识别误差）</p>
<p>当前点为p</p>
<p><strong>可达距离 &#x3D; max（o点的k - 距离，p到o之间的距离）</strong></p>
<p>简单来讲：可达距离 &#x3D; max (邻居的 k - 距离，点到邻居的实际距离)</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/18.png" class="" title="图片描述">

<p><strong>step4：</strong></p>
<p><strong>局部可达密度（LRD）：邻居到该点的平均可达距离的倒数（密度越高，值越大）</strong></p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/19.png" class="" title="图片描述">

<p><strong>step5：</strong></p>
<p><strong>计算局部离群因子（LOF）</strong></p>
<p>LOF接近于1——为正常点</p>
<p>LOF&gt;1——为异常点</p>
<p>LOF值越大，离群程度越高</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/20.png" class="" title="图片描述">

<ul>
<li>k值的影响：k太小，局部信息不够，容易误判；k值越大，异常点会被漏掉</li>
</ul>
<h4 id="3）基于聚类检测异常值（k-means聚类）"><a href="#3）基于聚类检测异常值（k-means聚类）" class="headerlink" title="3）基于聚类检测异常值（k - means聚类）"></a>3）基于聚类检测异常值（k - means聚类）</h4><ul>
<li><h5 id="k-means聚类定义："><a href="#k-means聚类定义：" class="headerlink" title="k - means聚类定义："></a>k - means聚类定义：</h5></li>
</ul>
<p>把所有数据点分为k个簇（k个小团体），计算每个点到自己所属簇的中心的距离，根据这一距离设定阈值，大于这一阈值的被称为离群点。</p>
<p>阈值选择：</p>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/21.png" class="" title="图片描述">

<ul>
<li><h5 id="k-means聚类的优缺点："><a href="#k-means聚类的优缺点：" class="headerlink" title="k - means聚类的优缺点："></a>k - means聚类的优缺点：</h5></li>
</ul>
<img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/22.png" class="" title="图片描述">

<h4 id="3）基于聚类检测异常值（DBSCAN聚类）"><a href="#3）基于聚类检测异常值（DBSCAN聚类）" class="headerlink" title="3）基于聚类检测异常值（DBSCAN聚类）"></a>3）基于聚类检测异常值（DBSCAN聚类）</h4><ul>
<li><h5 id="DBSCAN聚类定义："><a href="#DBSCAN聚类定义：" class="headerlink" title="DBSCAN聚类定义："></a>DBSCAN聚类定义：</h5></li>
</ul>
<p>两个重要参数：<strong>最小邻居数（MinPts）</strong>；<strong>半径参数（eps）</strong></p>
<p>对每个数据点，DBSCAN通过检查它在半径（eps）范围内的邻居数是否达到最小邻居数（&gt;&#x3D;MinPts）来判断这一数据点是否为核心点。</p>
<ul>
<li>&gt;&#x3D;MinPts 则为核心点；&lt;MinPts则为噪声点。</li>
</ul>
<h5 id="优缺点："><a href="#优缺点：" class="headerlink" title="优缺点："></a>优缺点：</h5><img src="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/23.png" class="" title="图片描述">

<h3 id="3、异常值的处理"><a href="#3、异常值的处理" class="headerlink" title="3、异常值的处理"></a>3、异常值的处理</h3><ul>
<li><strong>直接删除</strong></li>
<li>**异常值替换：**均值替换；中位数替换；截断（超过异常值边界的值用边界值代替）</li>
<li>**异常值修正：**对数变化（减少右偏分布的影响）；平方根变换（适用于轻微偏移的数据）；Box-Cox变换（通过参数调整数据分布，使其更接近正态分布）</li>
<li><strong>分离异常值单独分析</strong></li>
</ul>
<h5 id="异常值处理的影响评估："><a href="#异常值处理的影响评估：" class="headerlink" title="异常值处理的影响评估："></a>异常值处理的影响评估：</h5><ul>
<li><strong>可视化图表</strong>（直方图；QQ图——验证正态性）</li>
<li><strong>统计量量化</strong>（均值，方差，偏度的变化）</li>
<li><strong>模型性能的前后验证</strong>：如线性回归模型的R2变化；k - means聚类的轮廓系数变化</li>
</ul>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E7%AC%94%E8%AE%B0/" style="color: #00a596">笔记</a>
        </span>
        
    </div>
    <a href="/2025/12/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%9F%BA%E7%A1%80/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">
        <h2 class="post-title">大数据探索性分析课程笔记</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                复习笔记
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/12/9
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="数据配平"><a href="#数据配平" class="headerlink" title="数据配平"></a>数据配平</h2><h3 id="一、数据配平定义"><a href="#一、数据配平定义" class="headerlink" title="一、数据配平定义"></a>一、数据配平定义</h3><p>数据配平是针对于机器学习中“类别不平衡”问题的关键预处理技术，通过调整不同类别的样本分布比例，使模型能够提升对少数类样本的识别能力。</p>
<p>例如：想象你要训练一个 “识别人” 的模型：如果给它 1000 张男生照片、只给 1 张女生照片，模型练完后大概率只会认男生 —— 因为它见太多男生、没学过女生的特征，这就是 “类别不平衡”。</p>
<h5 id="类别不平衡的危害："><a href="#类别不平衡的危害：" class="headerlink" title="类别不平衡的危害："></a>类别不平衡的危害：</h5><ul>
<li>模型对于少数类的预测能力较差</li>
<li>在不平衡数据集上，常用的准确率指标可能误导分析</li>
<li>实际场景中漏检关键少数类</li>
</ul>
<h3 id="二、欠采样-删"><a href="#二、欠采样-删" class="headerlink" title="二、欠采样 - 删"></a>二、欠采样 - 删</h3><h5 id="定义：通过减少多数类样本的样本数量来平衡数据集"><a href="#定义：通过减少多数类样本的样本数量来平衡数据集" class="headerlink" title="定义：通过减少多数类样本的样本数量来平衡数据集"></a>定义：通过减少多数类样本的样本数量来平衡数据集</h5><ul>
<li>随机欠采样：随机删除多数类样本，使两类样本数量接近</li>
<li>基于聚类的欠采样：对多数类样本聚类（K - means），仅保留簇中心样本</li>
</ul>
<p>注：这里K - means聚类就是将多数类分为多个簇，每个簇保留中心样本</p>
<h5 id="欠采样的缺点"><a href="#欠采样的缺点" class="headerlink" title="欠采样的缺点"></a>欠采样的缺点</h5><p>删去样本可能会丢失有价值的信息；同时数据量的减少还会导致模型泛化能力下降</p>
<h5 id="解决欠采样导致的信息缺失方法："><a href="#解决欠采样导致的信息缺失方法：" class="headerlink" title="解决欠采样导致的信息缺失方法："></a>解决欠采样导致的信息缺失方法：</h5><ul>
<li><p>Bagging法：对多数类进行多次有放回的欠采样，从而得到多个不同的训练集，对这些不同训练集建立模型（也叫训练出多个分类器），最后综合得到的结果。</p>
<p>即：多次有放回欠采样，多模型组合</p>
</li>
<li><p>Boosting法：先通过一次欠采样得到训练集，并建立模型训练出一个分类器；然后从一开始的样本集中删掉第一次用掉的这些样本，对剩下的样本再次欠采样重复上面的步骤，最后综合得到结果。</p>
<p>即：逐步删除已经学会的多数类样本，多模型迭代</p>
</li>
</ul>
<h3 id="三、过采样-补"><a href="#三、过采样-补" class="headerlink" title="三、过采样 - 补"></a>三、过采样 - 补</h3><h5 id="定义：增加少数类样本数量来平衡数据集"><a href="#定义：增加少数类样本数量来平衡数据集" class="headerlink" title="定义：增加少数类样本数量来平衡数据集"></a>定义：增加少数类样本数量来平衡数据集</h5><ul>
<li><p>随机过采样：直接复制少数类样本（比如把 100 个少数类复制 9 次变 1000 个）</p>
<ul>
<li>优点：简单快速</li>
<li>缺点：导致样本重复，使模型在新数据上泛化能力差</li>
</ul>
</li>
<li><p>SMOTE方法：仿照少数类样本，造与他们相似的新样本</p>
<ul>
<li>优点：样本多样</li>
<li>缺点：可能偏离真实数据分布</li>
</ul>
</li>
</ul>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/1.png" class="" title="图片描述">

<h3 id="四、加权损失函数"><a href="#四、加权损失函数" class="headerlink" title="四、加权损失函数"></a>四、加权损失函数</h3><p>解释：对少数类样本赋予更大的权重</p>
<p>优：不引入新样本，不改变数据分布，模型保持原有结构</p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>模型预测值和真实值的差</p>
<h2 id="五、对模型的评估和优化"><a href="#五、对模型的评估和优化" class="headerlink" title="五、对模型的评估和优化"></a>五、对模型的评估和优化</h2><p>如何判断分类模型好不好？（特别是当样本不均衡的时候）</p>
<h3 id="1）混淆矩阵"><a href="#1）混淆矩阵" class="headerlink" title="1）混淆矩阵"></a>1）混淆矩阵</h3><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/4.png" class="" title="图片描述">

<p>总结：</p>
<p>情境：二分类问题，所有样本为两类之一：正例、负例</p>
<ul>
<li>TP：真实值为正例；预测值为正例 —— 预测正确</li>
<li>FP：真实值为负例；预测值为正例 —— 将多数样本判为少数样本（误报）</li>
<li>FN：真实值为正例；预测值为负例 —— 漏掉少数样本（漏报）</li>
<li>TN：真实值为负例；预测值为负例 —— 预测正确</li>
</ul>
<h3 id="2）准确率"><a href="#2）准确率" class="headerlink" title="2）准确率"></a>2）准确率</h3><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/5.png" class="" title="图片描述">

<p>即：混淆矩阵（左上+右下）&#x2F;（总样本数）</p>
<h3 id="3）精准率"><a href="#3）精准率" class="headerlink" title="3）精准率"></a>3）精准率</h3><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/6.png" class="" title="图片描述">

<p>即：混淆矩阵（左上）&#x2F;（左上+左下）</p>
<p>注：误报（FP）（左下）成本高的场景，追求高精准率</p>
<h3 id="4）召回率"><a href="#4）召回率" class="headerlink" title="4）召回率"></a>4）召回率</h3><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/7.png" class="" title="图片描述">

<p>即：混淆矩阵（左上）&#x2F;（左上+右上）</p>
<p>注：漏报（FN）（右上）成本高的场景，追求高召回率</p>
<h3 id="5）F1得分-兼顾精准率与召回率"><a href="#5）F1得分-兼顾精准率与召回率" class="headerlink" title="5）F1得分 - 兼顾精准率与召回率"></a>5）F1得分 - 兼顾精准率与召回率</h3><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/8.png" class="" title="图片描述">

<h3 id="6）ROC曲线"><a href="#6）ROC曲线" class="headerlink" title="6）ROC曲线"></a>6）ROC曲线</h3><h5 id="分类阈值"><a href="#分类阈值" class="headerlink" title="分类阈值"></a>分类阈值</h5><p>模型的分类结果依赖于一个分类阈值，如：结果为正例的概率超过0.5就预测为正例。</p>
<h4 id="ROC曲线的两个指标"><a href="#ROC曲线的两个指标" class="headerlink" title="ROC曲线的两个指标"></a>ROC曲线的两个指标</h4><ul>
<li>TPR（True Positive Rate）&#x3D; 召回率 &#x3D; 混淆矩阵（左上）&#x2F;（左上+右上）</li>
<li>FPR（False Positive Rate）（误报率）&#x3D; 混淆矩阵（左下）&#x2F;（左下+右下）</li>
</ul>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/10.png" class="" title="图片描述">

<h4 id="ROC曲线画图"><a href="#ROC曲线画图" class="headerlink" title="ROC曲线画图"></a>ROC曲线画图</h4><p>ROC曲线是一条以FPR为横坐标，TPR为纵坐标的曲线。</p>
<p>即：通过不断调整模型的分类阈值，会得到一系列（FPR，TPR）的点，这些点组成了ROC曲线。</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/9.png" class="" title="图片描述">

<ul>
<li>模型分类阈值高时，靠近左下（0，0）</li>
<li>模型分类阈值低时，靠近右上（1，1）</li>
</ul>
<p>好的二分类模型的ROC曲线应该急剧向上凸，快速接近左上角（即：当FPR低的时候就有高的TPR）</p>
<h4 id="AUC：ROC曲线下面部分的面积"><a href="#AUC：ROC曲线下面部分的面积" class="headerlink" title="AUC：ROC曲线下面部分的面积"></a>AUC：ROC曲线下面部分的面积</h4><p>作用：用于衡量分类器的性能</p>
<ul>
<li>AUC &#x3D; 1：完美分类器</li>
<li>AUC &#x3D; 0.5：随机猜测模型（模型没有任何区分能力）</li>
<li>AUC &lt; 0.5：无效模型</li>
</ul>
<h2 id="特征变换"><a href="#特征变换" class="headerlink" title="特征变换"></a>特征变换</h2><h3 id="一、特征变换定义："><a href="#一、特征变换定义：" class="headerlink" title="一、特征变换定义："></a>一、特征变换定义：</h3><p>将原始数据中的特征转化为更适合模型使用的形式，通过改变特征分布或表现形式，但不改变信息本质。</p>
<h4 id="特征工程："><a href="#特征工程：" class="headerlink" title="特征工程："></a>特征工程：</h4><ul>
<li>特征变换：改变已有特征</li>
<li>特征选择：筛选出最重要的特征</li>
<li>特征提取：把多个特征浓缩为少数几个</li>
</ul>
<h5 id="为什么做特征变换："><a href="#为什么做特征变换：" class="headerlink" title="为什么做特征变换："></a>为什么做特征变换：</h5><ul>
<li>适应模型的尺度敏感性</li>
<li>解决数据分布失衡</li>
<li>建模非线性关系</li>
<li>处理非数值特征</li>
<li>提升建模收敛速度</li>
</ul>
<h3 id="二、解决尺度差异："><a href="#二、解决尺度差异：" class="headerlink" title="二、解决尺度差异："></a>二、解决尺度差异：</h3><h4 id="1）标准化"><a href="#1）标准化" class="headerlink" title="1）标准化"></a>1）标准化</h4><p>即：将原来所有特征全部统一改为 - 均值为0、标准差为1的统一标准</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/11.png" class="" title="图片描述">

<p>特点：不改变数据分布，只改变尺度和中心；对异常值敏感</p>
<h4 id="2）归一化"><a href="#2）归一化" class="headerlink" title="2）归一化"></a>2）归一化</h4><p>定义：将数据按比例压缩到一个固定范围</p>
<h5 id="Min-Max-Scaling（最小最大归一化）-常用"><a href="#Min-Max-Scaling（最小最大归一化）-常用" class="headerlink" title="Min-Max Scaling（最小最大归一化）- 常用"></a>Min-Max Scaling（最小最大归一化）- 常用</h5><p>将数据按比例压缩到 [0,1] 的范围</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/12.png" class="" title="图片描述">

<p>缺点：容易受极端值的影响，若数据中存在异常值，归一化后的数据分布可能不均匀</p>
<p>当存在异常值时用鲁棒缩放</p>
<h5 id="最大绝对值缩放"><a href="#最大绝对值缩放" class="headerlink" title="最大绝对值缩放"></a>最大绝对值缩放</h5><p>将数据按比例压缩到 [-1,1]</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/13.png" class="" title="图片描述">

<h5 id="鲁棒缩放（Robust-Scaling）-针对含异常值的数据"><a href="#鲁棒缩放（Robust-Scaling）-针对含异常值的数据" class="headerlink" title="鲁棒缩放（Robust Scaling）- 针对含异常值的数据"></a>鲁棒缩放（Robust Scaling）- 针对含异常值的数据</h5><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/14.png" class="" title="图片描述">

<p>这里 IQR 指的是四分位距：</p>
<p>简单说就是数据中 “中间 50% 的数的范围”—— 先把数据从小到大排序，取第 75% 位置的数（上四分位数 Q3）减去第 25% 位置的数（下四分位数 Q1），即 IQR &#x3D; Q3 - Q1。</p>
<h3 id="三、改善分布"><a href="#三、改善分布" class="headerlink" title="三、改善分布"></a>三、改善分布</h3><h5 id="1）对数变换-压缩数据尺度"><a href="#1）对数变换-压缩数据尺度" class="headerlink" title="1）对数变换 - 压缩数据尺度"></a>1）对数变换 - 压缩数据尺度</h5><img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/15.png" class="" title="图片描述">

<h5 id="2）BOX-COX变换"><a href="#2）BOX-COX变换" class="headerlink" title="2）BOX - COX变换"></a>2）BOX - COX变换</h5><p>目标：将非正态分布数据转换为近似正态分布数据</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/16.png" class="" title="图片描述">

<h5 id="3）离散化-分箱"><a href="#3）离散化-分箱" class="headerlink" title="3）离散化 &#x3D; 分箱"></a>3）离散化 &#x3D; 分箱</h5><p>定义：将连续不断的数值特征划分为有限个区间；并将每个区间映射为一个离散值的过程</p>
<p>数据预处理阶段：</p>
<ul>
<li><p>**等宽分箱：**将值域范围划分为K个等宽的区间，宽度 &#x3D; （max - min）&#x2F;  K</p>
<ul>
<li>缺点：对异常值敏感；导致数据分布不均</li>
</ul>
</li>
<li><p>**等频分箱：**将数据划分为K个区间，使得每个区间包含样本数相同</p>
<ul>
<li>分界点选择：数据的分位数</li>
</ul>
</li>
<li><p>基于业务知识&#x2F;模型性能的分箱</p>
</li>
</ul>
<h5 id="4）离散化的作用："><a href="#4）离散化的作用：" class="headerlink" title="4）离散化的作用："></a>4）离散化的作用：</h5><ul>
<li>引入非线性关系</li>
<li>改善特征分布 - 将非正态分布的数据转化为(近)均匀分布</li>
<li>提高模型鲁棒性 - 限制离散值与噪声的影响</li>
<li>便于特征交叉与解释 - 特征组合</li>
</ul>
<h3 id="四、类别特征编码"><a href="#四、类别特征编码" class="headerlink" title="四、类别特征编码"></a>四、类别特征编码</h3><h4 id="1）独热编码（One-Hot-Encoding）"><a href="#1）独热编码（One-Hot-Encoding）" class="headerlink" title="1）独热编码（One - Hot Encoding）"></a>1）独热编码（One - Hot Encoding）</h4><p>定义：为每个类别建二值列，样本属于该类别则列值为 1，否则为 0</p>
<p>人话：将类别型特征变为模型能读懂的数字形式，通过给每个类别单独建一列，样本属于哪个类别，对应列标“1”，其他列标“0”</p>
<p>案例：</p>
<img src="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/17.png" class="" title="图片描述">

<p>特点：</p>
<ul>
<li>平等对待所有类别</li>
<li>缺点1：类别数量多时，会增加数据集维度</li>
<li>缺点2：多重共线性（比如 3 个类别列的和永远是 1（因为一个样本只能属于一个类别），会让模型计算出问题）<ul>
<li>解决方法：哑变量编码（去掉其中一列，这一列代表类别用其他列表示）</li>
</ul>
</li>
<li>缺点3：特征重要性分散</li>
</ul>
<h4 id="2）序数编码"><a href="#2）序数编码" class="headerlink" title="2）序数编码"></a>2）序数编码</h4><p>定义：处理”有顺序的类别特征“，把有序类别（如小学→中学→大学）映射成有序整数（1→2→3），保留类别间的顺序关系。</p>
<p>优点：</p>
<ul>
<li>保留顺序信息</li>
<li>避免维度爆炸</li>
</ul>
<p>缺点：</p>
<ul>
<li>隐含”数值距离相等“假设</li>
<li>类别数量多时，过度关注数值大小，忽略类别本身意义</li>
<li>测试集可能出现新类别<ul>
<li>预先定义完整的类别顺序</li>
<li>制定规则处理未知类别</li>
</ul>
</li>
</ul>
<h4 id="3）频率编码"><a href="#3）频率编码" class="headerlink" title="3）频率编码"></a>3）频率编码</h4><p>定义：将分类变量替换为它在数据集中出现的频率</p>
<p>注：频率本身带有预测信息，如：比如 “Chrome 浏览器” 出现频率高，说明它是主流浏览器，可能对应 “年轻用户” 等特征，模型能利用这种 “常见程度” 的信号</p>
<p>适用场景：类别出现频率本身具有信息量时</p>
<p>缺点：丢失类别本身的信息（如果两个不同类别出现频率一样（比如 “Firefox” 和 “Edge” 都出现 200 次，编码都是 0.2），模型会把它们当成同一个特征）</p>
<p>注：只能在训练集上计算频率，防止数据泄露</p>
<h4 id="4）目标编码"><a href="#4）目标编码" class="headerlink" title="4）目标编码"></a>4）目标编码</h4><p>定义：用“类别对应的目标变量统计值”代替类别标签</p>
<p>如：比如预测 “用户是否购买商品”（目标是 “购买 &#x2F; 不购买”），对 “城市” 这个类别特征，计算每个城市的 “购买率”（目标变量的期望值），用这个购买率作为该城市的编码值。</p>
<p>优点：</p>
<ul>
<li>直接编码类别与目标变量之间的统计关系，为模型提供了强烈的预测信号</li>
<li>编码值具有明确的业务含义</li>
</ul>
<p>适用条件：需要足够样本量支撑</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E7%AC%94%E8%AE%B0/" style="color: #ffa2c4">笔记</a>
        </span>
        
    </div>
    <a href="/2025/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%E6%80%A7%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/">
        <h2 class="post-title">机器学习习题</h2>
    </a>
    <div class="category-and-date">
        
        <span class="category">
            <a href="/categories/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                复习笔记
            </a>
        </span>
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/12/8
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><p>1）监督学习中，数据样本不仅包含属性特征变量，还包含：<u>相应的类别或数值标签</u></p>
<p>2）监督学习中，根据<u>输出空间</u>不同，可以将其分为哪两类问题：<u>回归问题&amp;分类问题</u></p>
<p>3）监督学习的模型评估中，常用的量化指标包括：绝对损失函数、平方损失函数、0-1损失函数、指数损失函数、合页损失函数</p>
<p>4）关于模型的方差-偏差折中思想：<u>方差项</u>主要由<u>抽样</u>带来，<u>偏差项</u>主要由<u>模型选择</u>带来</p>
<p>5）正则化方法中，<u>岭回归</u>采用的正则化项为：参数的<u>平方和</u>（L2范数）</p>
<p>6）<u>套索回归</u>中，为选择稀疏模型，正则化项采用：参数的<u>绝对和</u>（L1范数）</p>
<h3 id="补充知识点："><a href="#补充知识点：" class="headerlink" title="补充知识点："></a>补充知识点：</h3><p>1）监督学习中，数据样本包括：1.属性特征变量；2.相应类别；3.数据标签</p>
<p>2）监督学习定义：从标注数据中，学习预测模型；学习输入与输出间的对应关系；预测给定输入产生的输出</p>
<p>3）回归问题的输出空间由连续数值构成；分类问题~~由离散数值构成</p>
<p>4）风险函数&#x3D;期望损失：总体理论平均损失</p>
<p>模型学习目标：最小化风险函数（逐点最小化条件期望损失）</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/2.png" class="" title="图片描述">

<ul>
<li>离散分布求和；连续分布求导</li>
</ul>
<p>5）经验风险&#x3D;经验损失：样本实际平均损失</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/3.png" class="" title="图片描述">

<p>6）辨别概念：</p>
<p>第一组：</p>
<ul>
<li>拟合能力：对<u>已知</u>数据的预测能力</li>
<li>泛化能力：对<u>未知</u>数据的预测能力</li>
</ul>
<p>第二组：</p>
<ul>
<li>拟合误差：所有已知数据的平均损失</li>
<li>泛化误差：所有未知数据的平均损失</li>
</ul>
<p>第三组：</p>
<ul>
<li>训练误差：训练集的平均损失</li>
<li>测试误差：测试集的平均损失</li>
</ul>
<p>第四组：</p>
<ul>
<li>拟合误差是拟合能力的理论值，训练误差是其经验值</li>
<li>泛化误差是泛化能力的理论值，测试误差是其经验值</li>
</ul>
<p>7）总损失（<u>调整参数 的作用：平衡训练误差和测试误差</u>）</p>
<p>公式：总损失 &#x3D; 训练误差 + 调整参数 * 测试误差</p>
<p>注意：调整参数越大，越看重测试误差</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/4.png" class="" title="图片描述">

<p>模型学习目标：总损失最小</p>
<p>8）结构风险（<u>正则化方法的核心目的：平衡拟合能力和泛化能力</u>）</p>
<p>公式：结构风险 &#x3D; 经验风险 + 调整参数 * 模型复杂度（即正则化项）</p>
<p>注意：模型越复杂，越不好；调整参数越大，越不好</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/5.png" class="" title="图片描述">

<p>9）概念区分：</p>
<ul>
<li>过拟合：模型结构太复杂</li>
<li>欠拟合：模型结构太简单</li>
</ul>
<p>10）正则项：J(f) </p>
<ul>
<li><p>目的：在经验风险基础上对模型的复杂度施加惩罚</p>
</li>
<li><p>模型参数越多，模型越复杂，正则项越大</p>
</li>
</ul>
<p>11）正则化项在不同模型情况下的采用</p>
<ul>
<li>套索回归：参数绝对值之和</li>
<li>岭回归：参数的平方和</li>
</ul>
<h2 id="第二章：线性回归模型"><a href="#第二章：线性回归模型" class="headerlink" title="第二章：线性回归模型"></a>第二章：线性回归模型</h2><p>1）线性回归模型结构</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/6.png" class="" title="图片描述">

<p>2）线性回归模型的优缺点</p>
<ul>
<li>优：1.结构简单；2.易于理解；3.可解释性强</li>
<li>缺：对线性假设不稳定</li>
</ul>
<h4 id="线性回归中的最小二乘法"><a href="#线性回归中的最小二乘法" class="headerlink" title="线性回归中的最小二乘法"></a>线性回归中的最小二乘法</h4><ul>
<li>最小二乘法的核心：找一条最贴合数据的平面&#x2F;直线，使得预测值和实际值的误差最小</li>
</ul>
<p>1）偏差平方和</p>
<ul>
<li>偏差：实际值与模型算出来的值的差</li>
<li>偏差平方和：所有偏差的平方和</li>
</ul>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/7.png" class="" title="图片描述">

<p>2）二元线性回归中的样本偏差</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/8.png" class="" title="图片描述">

<p>3）多元线性回归的样本形式</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/9.png" class="" title="图片描述">

<p>其中里面的【误差项】需要满足高斯 - 马尔可夫假设：</p>
<ul>
<li>零均值：误差项整体不偏</li>
<li>等方差：每个数据的误差波动差不多</li>
<li>不相关：一个样本的误差与另一个样本的误差之间没有关系</li>
</ul>
<p>4）多元线性回归方程的矩阵形式</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/10.png" class="" title="图片描述">

<p>5）偏差平方和</p>
<p>模型算出来的值：预测值</p>
<p>偏差：预测值与实际值的差</p>
<p>偏差平方和：所有偏差的平方和</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/11.png" class="" title="图片描述">

<p>6）最小二乘估计</p>
<p>核心目标：让偏差平方和最小</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/12.png" class="" title="图片描述">

<p>7）最小二乘的求解过程</p>
<ul>
<li>展开偏差平方和</li>
</ul>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/13.png" class="" title="图片描述">

<ul>
<li>费马原理：求导，令导数 &#x3D; 0</li>
</ul>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/14.png" class="" title="图片描述">

<ul>
<li>解方程求最优参数</li>
</ul>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/15.png" class="" title="图片描述">

<ul>
<li>代回模型得到预测值</li>
</ul>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/16.png" class="" title="图片描述">

<p>8）例题：</p>
<p>题干：</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/17.png" class="" title="图片描述">

<p>解答：</p>
<p>step1：先求出偏差</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/19.png" class="" title="图片描述">

<p>step2：求出偏差平方和</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/20.png" class="" title="图片描述">

<p>step3：费马原理求导</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/21.png" class="" title="图片描述">

<h2 id="第三章：K近邻模型"><a href="#第三章：K近邻模型" class="headerlink" title="第三章：K近邻模型"></a>第三章：K近邻模型</h2><p>1）答案：C</p>
<img src="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/1.png" class="" title="图片描述">


            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        
        <span class="tag">
            
            <a href="/tags/%E7%AC%94%E8%AE%B0/" style="color: #ffa2c4">笔记</a>
        </span>
        
    </div>
    <a href="/2025/12/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%A0%E9%A2%98/" class="go-post">阅读全文</a>
</div>


        <div class="page-current">
    
    <span class="current">1</span>
    
    <a class="page-num" href="/page/2">
        2
    </a>
    
    
    
    
    <a class="page-num" href="/page/2/">
        <i class="fa-solid fa-caret-right fa-fw"></i>
    </a>
    
</div>

    </div>
    
    <div id="home-card">
        <div id="card-style">
    <div id="card-div">
        <div class="avatar">
            <img src="/images/xnylh.webp" alt="avatar" />
        </div>
        <div class="name">Leo yu yty</div>
        <div class="description">
            <p>yty的个人博客~<br>分享日常和学习心得</p>

        </div>
        
        
        <div class="friend-links">
            
            <div class="friend-link">
                <a target="_blank" rel="noopener" href="https://argvchs.github.io">Argvchs</a>
            </div>
            
            <div class="friend-link">
                <a target="_blank" rel="noopener" href="https://blog.csdn.net/leo_yty?spm=1000.2692.3001.5343">yty的csdn博客</a>
            </div>
            
        </div>
        
    </div>
</div>

    </div>
    
</div>

            <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2005 - 2025 yty的博客
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;Leo yu yty
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

        </div>
        
        <transition name="fade">
            <div id="preview" ref="preview" v-show="previewShow">
                <img id="preview-content" ref="previewContent" />
            </div>
        </transition>
        
    </div>
    <script src="/js/main.js"></script>
    
</body>
</html>
